{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"klueBERT_BoolQ.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1UEq0CyWk_jnR-d1ks7HADI-slj8ZH2Y5","authorship_tag":"ABX9TyPWDtScrKtHnJZ8Fowrs1jv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"883d0c871e4d4665b6d281caa1c3cbcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_547e149477044835a9284554fc6cbc4a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e5e4331f8b2409e9b8597e70af63942","IPY_MODEL_2466c3223a7248be8acf79acfe51d6d0","IPY_MODEL_0cb57d5625744c19861db296b89e6bba"]}},"547e149477044835a9284554fc6cbc4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e5e4331f8b2409e9b8597e70af63942":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1b743cb33ca4a1c878dee345604c018","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a8e23c0583b429eaa00e3d8cb9ebd16"}},"2466c3223a7248be8acf79acfe51d6d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_311056bf70d74fb3ad3de84152578ada","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":248477,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":248477,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbdb5fa47eeb40b2b8af255ef00b28ce"}},"0cb57d5625744c19861db296b89e6bba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c76c9c2a3c43490ebb31403b2cc4d49a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 248k/248k [00:00&lt;00:00, 668kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d35052132d7b409dad5eba26c22cccac"}},"d1b743cb33ca4a1c878dee345604c018":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a8e23c0583b429eaa00e3d8cb9ebd16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"311056bf70d74fb3ad3de84152578ada":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dbdb5fa47eeb40b2b8af255ef00b28ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c76c9c2a3c43490ebb31403b2cc4d49a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d35052132d7b409dad5eba26c22cccac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fbbaefe7b4d40c699340a70ea6f2a08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6b906d6dfaa94c0cba82f27bb02b165a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_212424df613840ad8ad1a99346f5a623","IPY_MODEL_3887dfb415664a3e9c46f2f83207c878","IPY_MODEL_240708f24bb94fd1943c41dca58aa643"]}},"6b906d6dfaa94c0cba82f27bb02b165a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"212424df613840ad8ad1a99346f5a623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfaf822ad24a4dec91a67e4c6c9e15b0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd26b7e78a8b48babbe93e5fadc82ebd"}},"3887dfb415664a3e9c46f2f83207c878":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f953632a87c442b28dbbf02f21b8ca62","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bd87b33c9a54668a1f3ba4856bf500a"}},"240708f24bb94fd1943c41dca58aa643":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21f108193a754660a877537e3a87dfee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [00:00&lt;00:00, 5.03kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2246cc7619e4424ca4dbf596b5671db4"}},"cfaf822ad24a4dec91a67e4c6c9e15b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cd26b7e78a8b48babbe93e5fadc82ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f953632a87c442b28dbbf02f21b8ca62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bd87b33c9a54668a1f3ba4856bf500a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21f108193a754660a877537e3a87dfee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2246cc7619e4424ca4dbf596b5671db4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"074294bd3138422ba2902c57e63f5368":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3072e1c78f634107a4a1620c9b9b9552","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c7ffffb3d32b45e99662502b0b2dd5e5","IPY_MODEL_9c8ffa05e9914f4ebd1f080b374a9d04","IPY_MODEL_fd8f60f9d11249a5a7aaee3f92af53f2"]}},"3072e1c78f634107a4a1620c9b9b9552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7ffffb3d32b45e99662502b0b2dd5e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_15b6fa384fc44a06bf99af15352ea2ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_911d35520ed44cedbc215d0f1b224eb7"}},"9c8ffa05e9914f4ebd1f080b374a9d04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_40d260dad3f341c683a0359a7e9ae8db","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01466d939ec04aaab7d0309b6d4c5ee2"}},"fd8f60f9d11249a5a7aaee3f92af53f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8b9126088664b48b01d5722c9e6aa82","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 289/289 [00:00&lt;00:00, 11.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa84031ea52846e883c5e48c7a3d740b"}},"15b6fa384fc44a06bf99af15352ea2ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"911d35520ed44cedbc215d0f1b224eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40d260dad3f341c683a0359a7e9ae8db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01466d939ec04aaab7d0309b6d4c5ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8b9126088664b48b01d5722c9e6aa82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa84031ea52846e883c5e48c7a3d740b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af20a8888e194f01b633af2327ef40b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1f3314701354facab9925410bede5ed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3c26860f49e54a1b90ad873ae8c03db5","IPY_MODEL_0fdb1c559cfc422b96b1cbbd0ed60745","IPY_MODEL_5a4556edd83942a2a57f77c4095013c2"]}},"e1f3314701354facab9925410bede5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c26860f49e54a1b90ad873ae8c03db5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3fd8d81cf8c4e7aaa54d92acb0025cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88e641ac74c54368befcf5126fac423c"}},"0fdb1c559cfc422b96b1cbbd0ed60745":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_edb08a3fc16f4e44b5b25910fdf926ef","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":428,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":428,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86f07fb583e54d8db634fd1047d39194"}},"5a4556edd83942a2a57f77c4095013c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c29e2fa83b24d90b11b4a827e399816","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 428/428 [00:00&lt;00:00, 16.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_417308db0bd44b6bbcf9f2d360fb9919"}},"e3fd8d81cf8c4e7aaa54d92acb0025cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"88e641ac74c54368befcf5126fac423c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edb08a3fc16f4e44b5b25910fdf926ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"86f07fb583e54d8db634fd1047d39194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c29e2fa83b24d90b11b4a827e399816":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"417308db0bd44b6bbcf9f2d360fb9919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f568ed35fb9429a89d7a1376166f6ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5a4d790205a946a496db02927bcb26a6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_156d940b5eb74bfca263a0d0965ac67a","IPY_MODEL_c1124f77ea3e43d297d8313cfe7df592","IPY_MODEL_a0b4136dc101483792e355ae369d3ad2"]}},"5a4d790205a946a496db02927bcb26a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"156d940b5eb74bfca263a0d0965ac67a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa555062b17c4a09826b9267a5486a76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa75042b89974419b101b18ee5f5fef9"}},"c1124f77ea3e43d297d8313cfe7df592":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b07c46eede9b4299995b8da7a1270640","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":445025130,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":445025130,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23f9b288e7184e43ae9b1722a0c69e95"}},"a0b4136dc101483792e355ae369d3ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8367f163aaa4431d85b2b8cd8737ce81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 445M/445M [00:08&lt;00:00, 62.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1241e983a854eb48d0461ca4f58cfa6"}},"fa555062b17c4a09826b9267a5486a76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa75042b89974419b101b18ee5f5fef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b07c46eede9b4299995b8da7a1270640":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"23f9b288e7184e43ae9b1722a0c69e95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8367f163aaa4431d85b2b8cd8737ce81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1241e983a854eb48d0461ca4f58cfa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqztSfQ51yo0","executionInfo":{"status":"ok","timestamp":1632388022221,"user_tz":-540,"elapsed":12,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"898beb6e-3e53-4d8e-91ad-f1a1b9788a8b"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 23 09:07:01 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGvIo0gk1_EM","executionInfo":{"status":"ok","timestamp":1632388030549,"user_tz":-540,"elapsed":2493,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"9f78e6bf-98a3-4978-ae62-60f9ebe55466"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9pSkeLw2AZ_","executionInfo":{"status":"ok","timestamp":1632388040242,"user_tz":-540,"elapsed":6410,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"0ea6da09-72a7-4042-922f-89bf505fb8a5"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 62.2 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.8 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 68.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 92.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"r2-Zkk7x2Be5","executionInfo":{"status":"ok","timestamp":1632388043338,"user_tz":-540,"elapsed":421,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"d35e9817-389d-439f-dd2e-f5c7574f84d1"},"source":["import pandas as pd\n","\n","# Load the dataset into a pandas dataframe.\n","PATH = '/content/drive/MyDrive/gh/klue/DATA'\n","df = pd.read_csv(PATH + \"/BoolQ/SKT_BoolQ_Train.tsv\", sep='\\t')\n","\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# Display 10 random rows from the data.\n","df.sample(10)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training sentences: 3,665\n","\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","      <th>Question</th>\n","      <th>Answer(FALSE = 0, TRUE = 1)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2104</th>\n","      <td>2105</td>\n","      <td>중국은 오래전에 화약을 발명하여 포와 폭탄을 만들어 사용하였다. 원래는 종교적 목적...</td>\n","      <td>중국은 처음 화약을 군사적 목적으로 사용하기 위해 만들었는가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2489</th>\n","      <td>2490</td>\n","      <td>첫 왕비였던 공혜왕후가 18세의 나이에 요절하자 성종은 자신의 후궁 중 일찍 후궁으...</td>\n","      <td>성종은 왕비를 세 번 들였다.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2498</th>\n","      <td>2499</td>\n","      <td>정지 상태에서 움직이기 시작할 때나 속도가 변화할 때 등에 안쪽 림프가 그 반동으로...</td>\n","      <td>속도가 일정하더라도 움직이고 있다면 감각 세포는 자극을 받는다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>456</th>\n","      <td>457</td>\n","      <td>증기기관(蒸氣機關, 영어: Steam engine)은 외연 열기관으로, 수증기의 열...</td>\n","      <td>증기기관은 제임스 와트가 발명했는가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>1910년에 파리의 캉봉거리 21번지에 \" 샤넬 모드 \" 라는 모자 전문점을 개업한...</td>\n","      <td>샤넬이 만든 바지에 모든 여성들이 극찬했나요?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3500</th>\n","      <td>3501</td>\n","      <td>흰민들레는 원줄기 없이 모든 잎은 뿌리에서 나와 비스듬히 서며 자란다. 길이 7~2...</td>\n","      <td>흰민들레의 꽃은 겨울에 피나요?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2321</th>\n","      <td>2322</td>\n","      <td>2010년 4월을 기준으로, 젤다의 전설 시리즈는 첫번째 게임인 젤다의 전설 출시 ...</td>\n","      <td>젤다의 전설은 가장 많이 팔린 NES 소프트웨어이다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1978</th>\n","      <td>1979</td>\n","      <td>호흡기는 상부 기도와 하부 기도로 나뉜다. 상부 기도와 상부 호흡기는 코와 코, 부...</td>\n","      <td>기관은 상부 기도의 일부분인가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>993</th>\n","      <td>994</td>\n","      <td>과테말라 공화국(스페인어: República de Guatemala 레푸블리카 데 ...</td>\n","      <td>과테말라 공화국은 동쪽으로 태평양과 접하는가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>284</td>\n","      <td>낙서는 간단한 스크래치 표현에서부터 정교한 벽화에 이르기까지 다양한 종류가 포함될 ...</td>\n","      <td>에어로졸 스프레이를 이용한 낙서를 그라피티라고 칭하기도 한다.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        ID  ... Answer(FALSE = 0, TRUE = 1)\n","2104  2105  ...                           0\n","2489  2490  ...                           1\n","2498  2499  ...                           0\n","456    457  ...                           0\n","886    887  ...                           0\n","3500  3501  ...                           0\n","2321  2322  ...                           0\n","1978  1979  ...                           0\n","993    994  ...                           0\n","283    284  ...                           1\n","\n","[10 rows x 4 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"SGtlZVWH2Qn9","executionInfo":{"status":"ok","timestamp":1632388047801,"user_tz":-540,"elapsed":265,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"ba2ef0f9-baf4-4e6a-88bb-86db37fd4fc1"},"source":["df.loc[df['Answer(FALSE = 0, TRUE = 1)'] == 0].sample(5)[['Text','Question','Answer(FALSE = 0, TRUE = 1)']]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Question</th>\n","      <th>Answer(FALSE = 0, TRUE = 1)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2859</th>\n","      <td>에르메스는 프랑스에서 가방에 최초로 지퍼를 사용하여 만들어 보급하기도 했다. 이는 ...</td>\n","      <td>에르메스는 전 세계에서 최초로 지퍼를 사용했는가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1336</th>\n","      <td>염산은 주로 38%의 포화 농도의 염산을 생성하고 사용한다. 40% 또는 그 이상의...</td>\n","      <td>염산은 고온 상태에서 주로 생성되는가?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3009</th>\n","      <td>트로피칼리아(Tropicália)는 1960년대 후반에 생겨난 브라질의 예술 운동이...</td>\n","      <td>트로피칼리아는 브라질 전통만을 담고 있다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1779</th>\n","      <td>생태학에서 절멸 또는 멸종은 생존해 있던 종의 개체가 더 이상 세계에서 확인되지 않...</td>\n","      <td>야생 동물의 경우 멸종을 판단하기 쉽습니까?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1645</th>\n","      <td>백설기는 쌀가루 반죽으로 만든 한국의 시루떡이다. 백편, 흰무리떡, 설기라고도 한다...</td>\n","      <td>백설기는 이웃과 나누어 먹나요?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   Text  ... Answer(FALSE = 0, TRUE = 1)\n","2859  에르메스는 프랑스에서 가방에 최초로 지퍼를 사용하여 만들어 보급하기도 했다. 이는 ...  ...                           0\n","1336  염산은 주로 38%의 포화 농도의 염산을 생성하고 사용한다. 40% 또는 그 이상의...  ...                           0\n","3009  트로피칼리아(Tropicália)는 1960년대 후반에 생겨난 브라질의 예술 운동이...  ...                           0\n","1779  생태학에서 절멸 또는 멸종은 생존해 있던 종의 개체가 더 이상 세계에서 확인되지 않...  ...                           0\n","1645  백설기는 쌀가루 반죽으로 만든 한국의 시루떡이다. 백편, 흰무리떡, 설기라고도 한다...  ...                           0\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"vmRqbJEN2eAD","executionInfo":{"status":"ok","timestamp":1632388050349,"user_tz":-540,"elapsed":2,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["# Get the lists of sentences and their labels.\n","passages = df.Text.values\n","questions = df.Question.values\n","labels = df['Answer(FALSE = 0, TRUE = 1)'].values"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["883d0c871e4d4665b6d281caa1c3cbcd","547e149477044835a9284554fc6cbc4a","4e5e4331f8b2409e9b8597e70af63942","2466c3223a7248be8acf79acfe51d6d0","0cb57d5625744c19861db296b89e6bba","d1b743cb33ca4a1c878dee345604c018","8a8e23c0583b429eaa00e3d8cb9ebd16","311056bf70d74fb3ad3de84152578ada","dbdb5fa47eeb40b2b8af255ef00b28ce","c76c9c2a3c43490ebb31403b2cc4d49a","d35052132d7b409dad5eba26c22cccac","5fbbaefe7b4d40c699340a70ea6f2a08","6b906d6dfaa94c0cba82f27bb02b165a","212424df613840ad8ad1a99346f5a623","3887dfb415664a3e9c46f2f83207c878","240708f24bb94fd1943c41dca58aa643","cfaf822ad24a4dec91a67e4c6c9e15b0","cd26b7e78a8b48babbe93e5fadc82ebd","f953632a87c442b28dbbf02f21b8ca62","8bd87b33c9a54668a1f3ba4856bf500a","21f108193a754660a877537e3a87dfee","2246cc7619e4424ca4dbf596b5671db4","074294bd3138422ba2902c57e63f5368","3072e1c78f634107a4a1620c9b9b9552","c7ffffb3d32b45e99662502b0b2dd5e5","9c8ffa05e9914f4ebd1f080b374a9d04","fd8f60f9d11249a5a7aaee3f92af53f2","15b6fa384fc44a06bf99af15352ea2ac","911d35520ed44cedbc215d0f1b224eb7","40d260dad3f341c683a0359a7e9ae8db","01466d939ec04aaab7d0309b6d4c5ee2","d8b9126088664b48b01d5722c9e6aa82","fa84031ea52846e883c5e48c7a3d740b","af20a8888e194f01b633af2327ef40b3","e1f3314701354facab9925410bede5ed","3c26860f49e54a1b90ad873ae8c03db5","0fdb1c559cfc422b96b1cbbd0ed60745","5a4556edd83942a2a57f77c4095013c2","e3fd8d81cf8c4e7aaa54d92acb0025cc","88e641ac74c54368befcf5126fac423c","edb08a3fc16f4e44b5b25910fdf926ef","86f07fb583e54d8db634fd1047d39194","1c29e2fa83b24d90b11b4a827e399816","417308db0bd44b6bbcf9f2d360fb9919"]},"id":"AJ5vn8A323r-","executionInfo":{"status":"ok","timestamp":1632388056194,"user_tz":-540,"elapsed":5538,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"5aa40a12-f228-4493-fc4a-7227038600ef"},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"883d0c871e4d4665b6d281caa1c3cbcd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fbbaefe7b4d40c699340a70ea6f2a08","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"074294bd3138422ba2902c57e63f5368","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af20a8888e194f01b633af2327ef40b3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/428 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mR0aqc8s29ax","executionInfo":{"status":"ok","timestamp":1632387916526,"user_tz":-540,"elapsed":299,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"b59f0097-c710-406c-8586-e1689d25e691"},"source":["# Print the original sentence.\n","print(' Original: ', passages[0],questions[0])\n","\n","# Print the sentence split into tokens.\n","#print('Tokenized: ', tokenizer.tokenize(passages[0],questions[0]))\n","\n","# Print the sentence mapped to token ids.\n","#print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(passages[0],questions[0])))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original:  로마 시대의 오리엔트의 범위는 제국 내에 동부 지방은 물론 제국 외부에 있는 다른 국가에 광범위하게 쓰이는 단어였다. 그 후에 로마 제국이 분열되고 서유럽이 그들의 중심적인 세계를 형성하는 과정에서 자신들을 옥시덴트(occident), 서방이라 부르며 오리엔트는 이와 대조되는 문화를 가진 동방세계라는 뜻이 부가되어, 인도와 중국, 일본을 이루는 광범위한 지역을 지칭하는 단어가 되었다. 오리엔트는 인도와 중국, 일본을 이루는 광범위한 지역을 지칭하는 단어로 쓰인다.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NOdKx4GE3Wgi","executionInfo":{"status":"ok","timestamp":1632388063436,"user_tz":-540,"elapsed":3739,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"2af9ee02-dd95-48af-dacf-2a8eaf385adc"},"source":["max_len = 0\n","\n","# For every sentence...\n","for question, passage in zip(questions, passages):\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(question,passage, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Max sentence length:  267\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldhvmHRK3dEF","executionInfo":{"status":"ok","timestamp":1632388067848,"user_tz":-540,"elapsed":4428,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"28d6932f-ae80-4508-a153-5c2591e77be4"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for question, passage in zip(questions, passages):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        question,\n","                        passage,              # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","#print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Token IDs: tensor([    2, 19141,  2265,  2259,  4543,  2522,  3693,    16,  3708,  2069,\n","         4046,  2259,  9774,  2470,  3634,  2069, 11770,  2205,  2259,  5591,\n","         2200, 15166,    18,     3,  6335,  3891,  2079, 19141,  2265,  2079,\n","         5371,  2259,  6113,   732,  2170,  6369,  3870,  2073,  3843,  6113,\n","         4993,  2170,  1513,  2259,  3656,  3728,  2170,  9774,  2205,  2318,\n","         8026,  2259,  5591,  2507,  2062,    18,   636,  1943,  2170,  6335,\n","         6113,  2052,  7724,  2496,  2088, 20155,  2052,   636,  2031,  2079,\n","         3886, 31221,  3665,  2138,  4605,  2205,  2259,  3747, 27135,  3638,\n","         2031,  2069, 23636,  2906,  2265,    12,    82,  2046,  2046, 14811,\n","        30062,    13,    16,  9500,  2052,  2181,  4681,  2307, 19141,  2265,\n","         2259, 29162,  8782,  2496,  2259,  3697,  2138,  4398, 11685, 25832,\n","        23548,   936,  2052,  8073,  2496,  2051,    16,  4543,  2522,  3693,\n","           16,  3708,  2069,  4046,  2259,  9774,  2470,  3634,  2069, 11770,\n","         2205,  2259,  5591,  2116,   859,  2359,  2062,    18,     3,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yqmn5hht5BUM","executionInfo":{"status":"ok","timestamp":1632388075193,"user_tz":-540,"elapsed":255,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"cf47e989-dedd-42e0-c74d-ea7045aac036"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["3,298 training samples\n","  367 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"XblBrCx45zRy","executionInfo":{"status":"ok","timestamp":1632388080222,"user_tz":-540,"elapsed":261,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2f568ed35fb9429a89d7a1376166f6ab","5a4d790205a946a496db02927bcb26a6","156d940b5eb74bfca263a0d0965ac67a","c1124f77ea3e43d297d8313cfe7df592","a0b4136dc101483792e355ae369d3ad2","fa555062b17c4a09826b9267a5486a76","aa75042b89974419b101b18ee5f5fef9","b07c46eede9b4299995b8da7a1270640","23f9b288e7184e43ae9b1722a0c69e95","8367f163aaa4431d85b2b8cd8737ce81","d1241e983a854eb48d0461ca4f58cfa6"]},"id":"-C0apcWj51aG","executionInfo":{"status":"ok","timestamp":1632388100762,"user_tz":-540,"elapsed":17682,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"6efa33e0-7940-48ce-d583-be4f5e45e209"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"klue/bert-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f568ed35fb9429a89d7a1376166f6ab","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rn_sfHTv54d-","executionInfo":{"status":"ok","timestamp":1632388156221,"user_tz":-540,"elapsed":251,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"f229560c-4254-4c6a-c6b8-57768efc22fe"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (32000, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"code","metadata":{"id":"QdDgQcln55mz","executionInfo":{"status":"ok","timestamp":1632388160463,"user_tz":-540,"elapsed":250,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BdcUd1756l3","executionInfo":{"status":"ok","timestamp":1632388163411,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2kon0fs57oc","executionInfo":{"status":"ok","timestamp":1632388165312,"user_tz":-540,"elapsed":386,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xaL_4qd58eb","executionInfo":{"status":"ok","timestamp":1632388165565,"user_tz":-540,"elapsed":4,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUOnlP9-59b-","executionInfo":{"status":"ok","timestamp":1632388492721,"user_tz":-540,"elapsed":325460,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"cc0a171a-54d8-4efd-ac5e-fcb1e227a43d"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    104.    Elapsed: 0:00:31.\n","  Batch    80  of    104.    Elapsed: 0:01:01.\n","\n","  Average training loss: 0.71\n","  Training epcoh took: 0:01:18\n","\n","Running Validation...\n","  Accuracy: 0.61\n","  Validation Loss: 0.65\n","  Validation took: 0:00:03\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    104.    Elapsed: 0:00:30.\n","  Batch    80  of    104.    Elapsed: 0:01:01.\n","\n","  Average training loss: 0.59\n","  Training epcoh took: 0:01:18\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.58\n","  Validation took: 0:00:03\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    104.    Elapsed: 0:00:30.\n","  Batch    80  of    104.    Elapsed: 0:01:01.\n","\n","  Average training loss: 0.44\n","  Training epcoh took: 0:01:18\n","\n","Running Validation...\n","  Accuracy: 0.69\n","  Validation Loss: 0.62\n","  Validation took: 0:00:03\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    104.    Elapsed: 0:00:30.\n","  Batch    80  of    104.    Elapsed: 0:01:01.\n","\n","  Average training loss: 0.33\n","  Training epcoh took: 0:01:18\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.64\n","  Validation took: 0:00:03\n","\n","Training complete!\n","Total training took 0:05:25 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"dEjBw6Ae6rRB","executionInfo":{"status":"ok","timestamp":1632388873576,"user_tz":-540,"elapsed":263,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"036b8140-2b1e-443c-a281-bed1977c2a1e"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.71</td>\n","      <td>0.65</td>\n","      <td>0.61</td>\n","      <td>0:01:18</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.59</td>\n","      <td>0.58</td>\n","      <td>0.68</td>\n","      <td>0:01:18</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.44</td>\n","      <td>0.62</td>\n","      <td>0.69</td>\n","      <td>0:01:18</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.33</td>\n","      <td>0.64</td>\n","      <td>0.71</td>\n","      <td>0:01:18</td>\n","      <td>0:00:03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.71         0.65           0.61       0:01:18         0:00:03\n","2               0.59         0.58           0.68       0:01:18         0:00:03\n","3               0.44         0.62           0.69       0:01:18         0:00:03\n","4               0.33         0.64           0.71       0:01:18         0:00:03"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"yR28mZuF9XmP","executionInfo":{"status":"ok","timestamp":1632388879501,"user_tz":-540,"elapsed":1085,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"ccd6f17e-d8e6-434d-9cd3-8fae9478d7a3"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1iUV9rH8e8MwzBD70WKBaUKiIXEaGIsCInGFFuiiWmbxGzaJpuim2RT9s0WU4ymuBvTjSX2Eo29JKZhSTBKMXYQBKR3GOZ5/wBGRkBBwQG8P9e118KZp5wZPfHH4X7OUSmKoiCEEEIIIYToFNSW7oAQQgghhBCi5STACyGEEEII0YlIgBdCCCGEEKITkQAvhBBCCCFEJyIBXgghhBBCiE5EArwQQgghhBCdiAR4IcRVLz09neDgYN57771LvsaMGTMIDg5uw151Xc193sHBwcyYMaNF13jvvfcIDg4mPT29zfu3cuVKgoOD+eWXX9r82kII0RY0lu6AEEKcrzVBeNu2bfj5+bVjbzqfsrIy/vvf/7Jhwways7NxdXVlwIAB/PnPfyYwMLBF13jyySfZtGkTq1evJjQ0tMljFEVh5MiRFBUVsXv3bnQ6XVu+jXb1yy+/kJCQwL333oujo6Olu9NIeno6I0eOZOrUqfz973+3dHeEEB2MBHghRIcza9Yss+/37dvH119/zeTJkxkwYIDZa66urpd9P19fXw4cOICVldUlX+Mf//gHr7322mX3pS289NJLrF+/nrFjxxITE0NOTg7bt28nMTGxxQF+woQJbNq0iRUrVvDSSy81eczPP//M6dOnmTx5cpuE9wMHDqBWX5lfDCckJPD+++9z++23Nwrwt956K2PGjMHa2vqK9EUIIVpLArwQosO59dZbzb6vqanh66+/pl+/fo1eO19JSQn29vatup9KpcLGxqbV/Wyoo4S98vJyNm7cyNChQ3n77bdN7Y8//jhVVVUtvs7QoUPx8fFh3bp1PP/882i12kbHrFy5EqgN+23hcv8M2oqVldVl/TAnhBDtTWrghRCd1ogRI7jnnntISkriwQcfZMCAAYwbNw6oDfKzZ89m4sSJXHPNNfTt25fY2FjeeustysvLza7TVE12w7YdO3Ywfvx4IiIiGDp0KP/5z38wGAxm12iqBr6+rbi4mFdeeYXBgwcTERHBnXfeSWJiYqP3k5+fz8yZM7nmmmuIjo5m2rRpJCUlcc899zBixIgWfSYqlQqVStXkDxRNhfDmqNVqbr/9dgoKCti+fXuj10tKSti8eTNBQUFERka26vNuTlM18Eajkf/973+MGDGCiIgIxo4dy9q1a5s8/+jRo7z66quMGTOG6OhooqKiuOOOO1i2bJnZcTNmzOD9998HYOTIkQQHB5v9+TdXA5+Xl8drr73GsGHD6Nu3L8OGDeO1114jPz/f7Lj683/66Sc++eQTRo0aRd++fYmLi2PVqlUt+ixaIyUlhccee4xrrrmGiIgIbr75ZubPn09NTY3ZcZmZmcycOZPhw4fTt29fBg8ezJ133mnWJ6PRyOeff84tt9xCdHQ0/fv3Jy4ujr/97W9UV1e3ed+FEJdGZuCFEJ1aRkYG9957L/Hx8YwePZqysjIAsrKyWL58OaNHj2bs2LFoNBoSEhL4+OOPSU5O5pNPPmnR9Xft2sWiRYu48847GT9+PNu2bePTTz/FycmJ6dOnt+gaDz74IK6urjz22GMUFBTw2Wef8fDDD7Nt2zbTbwuqqqq4//77SU5O5o477iAiIoLU1FTuv/9+nJycWvx56HQ6brvtNlasWME333zD2LFjW3zu+e644w7mzZvHypUriY+PN3tt/fr1VFRUMH78eKDtPu/z/etf/+LLL79k0KBB3HfffeTm5vL666/j7+/f6NiEhAT27t3LjTfeiJ+fn+m3ES+99BJ5eXk88sgjAEyePJmSkhK2bNnCzJkzcXFxAS787EVxcTF33XUXJ0+eZPz48YSFhZGcnMzixYv5+eefWbZsWaPf/MyePZuKigomT56MVqtl8eLFzJgxg4CAgEalYJfq999/55577kGj0TB16lTc3d3ZsWMHb731FikpKabfwhgMBu6//36ysrKYMmUKPXr0oKSkhNTUVPbu3cvtt98OwLx585g7dy7Dhw/nzjvvxMrKivT0dLZv305VVVWH+U2TEFc9RQghOrgVK1YoQUFByooVK8zahw8frgQFBSlLly5tdE5lZaVSVVXVqH327NlKUFCQkpiYaGpLS0tTgoKClLlz5zZqi4qKUtLS0kztRqNRGTNmjDJkyBCz677wwgtKUFBQk22vvPKKWfuGDRuUoKAgZfHixaa2r776SgkKClI+/PBDs2Pr24cPH97ovTSluLhYeeihh5S+ffsqYWFhyvr161t0XnOmTZumhIaGKllZWWbtkyZNUsLDw5Xc3FxFUS7/81YURQkKClJeeOEF0/dHjx5VgoODlWnTpikGg8HUfvDgQSU4OFgJCgoy+7MpLS1tdP+amhrl7rvvVvr372/Wv7lz5zY6v17937eff/7Z1PbOO+8oQUFByldffWV2bP2fz+zZsxudf+uttyqVlZWm9jNnzijh4eHK008/3eie56v/jF577bULHjd58mQlNDRUSU5ONrUZjUblySefVIKCgpQff/xRURRFSU5OVoKCgpSPPvrogte77bbblJtuuumi/RNCWJaU0AghOjVnZ2fuuOOORu1ardY0W2gwGCgsLCQvL4/rrrsOoMkSlqaMHDnSbJUblUrFNddcQ05ODqWlpS26xn333Wf2/bXXXgvAyZMnTW07duzAysqKadOmmR07ceJEHBwcWnQfo9HIU089RUpKCt9++y033HADzz77LOvWrTM77uWXXyY8PLxFNfETJkygpqaG1atXm9qOHj3Kb7/9xogRI0wPEbfV593Qtm3bUBSF+++/36wmPTw8nCFDhjQ63tbW1vR1ZWUl+fn5FBQUMGTIEEpKSjh27Fir+1Bvy5YtuLq6MnnyZLP2yZMn4+rqytatWxudM2XKFLOyJS8vL3r27MmJEycuuR8N5ebm8uuvvzJixAhCQkJM7SqVikcffdTUb8D0d+iXX34hNze32Wva29uTlZXF3r1726SPQoj2ISU0QohOzd/fv9kHDhcuXMiSJUs4cuQIRqPR7LXCwsIWX/98zs7OABQUFGBnZ9fqa9SXbBQUFJja0tPT8fT0bHQ9rVaLn58fRUVFF73Ptm3b2L17N2+++SZ+fn7MmTOHxx9/nOeffx6DwWAqk0hNTSUiIqJFNfGjR4/G0dGRlStX8vDDDwOwYsUKAFP5TL22+LwbSktLA6BXr16NXgsMDGT37t1mbaWlpbz//vt8++23ZGZmNjqnJZ9hc9LT0+nbty8ajfk/mxqNhh49epCUlNTonOb+7pw+ffqS+3F+nwB69+7d6LVevXqhVqtNn6Gvry/Tp0/no48+YujQoYSGhnLttdcSHx9PZGSk6bxnnnmGxx57jKlTp+Lp6UlMTAw33ngjcXFxrXqGQgjRviTACyE6Nb1e32T7Z599xr///W+GDh3KtGnT8PT0xNramqysLGbMmIGiKC26/oVWI7nca7T0/Jaqf+hy0KBBQG34f//993n00UeZOXMmBoOBkJAQEhMTeeONN1p0TRsbG8aOHcuiRYvYv38/UVFRrF27Fm9vb66//nrTcW31eV+Ov/71r+zcuZNJkyYxaNAgnJ2dsbKyYteuXXz++eeNfqhob1dqScyWevrpp5kwYQI7d+5k7969LF++nE8++YQ//elPPPfccwBER0ezZcsWdu/ezS+//MIvv/zCN998w7x581i0aJHph1chhGVJgBdCdElr1qzB19eX+fPnmwWp7777zoK9ap6vry8//fQTpaWlZrPw1dXVpKent2izofr3efr0aXx8fIDaEP/hhx8yffp0Xn75ZXx9fQkKCuK2225rcd8mTJjAokWLWLlyJYWFheTk5DB9+nSzz7U9Pu/6Gexjx44REBBg9trRo0fNvi8qKmLnzp3ceuutvP7662av/fjjj42urVKpWt2X48ePYzAYzGbhDQYDJ06caHK2vb3Vl3YdOXKk0WvHjh3DaDQ26pe/vz/33HMP99xzD5WVlTz44IN8/PHHPPDAA7i5uQFgZ2dHXFwccXFxQO1vVl5//XWWL1/On/70p3Z+V0KIluhY0wNCCNFG1Go1KpXKbObXYDAwf/58C/aqeSNGjKCmpoYvv/zSrH3p0qUUFxe36BrDhg0Dalc/aVjfbmNjwzvvvIOjoyPp6enExcU1KgW5kPDwcEJDQ9mwYQMLFy5EpVI1Wvu9PT7vESNGoFKp+Oyzz8yWRDx06FCjUF7/Q8P5M/3Z2dmNlpGEc/XyLS3tGTVqFHl5eY2utXTpUvLy8hg1alSLrtOW3NzciI6OZseOHRw+fNjUrigKH330EQCxsbFA7So65y8DaWNjYypPqv8c8vLyGt0nPDzc7BghhOXJDLwQokuKj4/n7bff5qGHHiI2NpaSkhK++eabVgXXK2nixIksWbKEd999l1OnTpmWkdy4cSPdu3dvtO58U4YMGcKECRNYvnw5Y8aM4dZbb8Xb25u0tDTWrFkD1IaxDz74gMDAQG666aYW92/ChAn84x//4PvvvycmJqbRzG57fN6BgYFMnTqVr776invvvZfRo0eTm5vLwoULCQkJMas7t7e3Z8iQIaxduxadTkdERASnT5/m66+/xs/Pz+x5A4CoqCgA3nrrLW655RZsbGzo06cPQUFBTfblT3/6Exs3buT1118nKSmJ0NBQkpOTWb58OT179my3memDBw/y4YcfNmrXaDQ8/PDDvPjii9xzzz1MnTqVKVOm4OHhwY4dO9i9ezdjx45l8ODBQG151csvv8zo0aPp2bMndnZ2HDx4kOXLlxMVFWUK8jfffDP9+vUjMjIST09PcnJyWLp0KdbW1owZM6Zd3qMQovU65r9kQghxmR588EEURWH58uW88cYbeHh4cNNNNzF+/HhuvvlmS3evEa1WyxdffMGsWbPYtm0b3377LZGRkXz++ee8+OKLVFRUtOg6b7zxBjExMSxZsoRPPvmE6upqfH19iY+P54EHHkCr1TJ58mSee+45HBwcGDp0aIuue8sttzBr1iwqKysbPbwK7fd5v/jii7i7u7N06VJmzZpFjx49+Pvf/87JkycbPTj65ptv8vbbb7N9+3ZWrVpFjx49ePrpp9FoNMycOdPs2AEDBvDss8+yZMkSXn75ZQwGA48//nizAd7BwYHFixczd+5ctm/fzsqVK3Fzc+POO+/kiSeeaPXuvy2VmJjY5Ao+Wq2Whx9+mIiICJYsWcLcuXNZvHgxZWVl+Pv78+yzz/LAAw+Yjg8ODiY2NpaEhATWrVuH0WjEx8eHRx55xOy4Bx54gF27drFgwQKKi4txc3MjKiqKRx55xGylGyGEZamUK/FkkRBCiEtSU1PDtddeS2Rk5CVvhiSEEKJrkRp4IYToIJqaZV+yZAlFRUVNrnsuhBDi6iQlNEII0UG89NJLVFVVER0djVar5ddff+Wbb76he/fuTJo0ydLdE0II0UFICY0QQnQQq1evZuHChZw4cYKysjLc3NwYNmwYTz31FO7u7pbunhBCiA5CArwQQgghhBCdiNTACyGEEEII0YlIgBdCCCGEEKITkYdYWyk/vxSj8cpXHbm52ZObW3LF7ytEZyNjRYiWkbEiRMtYYqyo1SpcXOyafV0CfCsZjYpFAnz9vYUQFydjRYiWkbEiRMt0tLEiJTRCCCGEEEJ0IhLghRBCCCGE6EQkwAshhBBCCNGJSIAXQgghhBCiE5EAL4QQQgghRCciq9AIIYQQQrSB8vJSSkoKqamptnRXRBvKzlZjNBrb7HpWVtbY2zuh1ze/TOTFSIAXQgghhLhM1dVVFBfn4+zsjrW1DSqVytJdEm1Eo1FjMLRNgFcUherqSgoKzqLRWGNtrb2k60gJjRBCCCHEZSouLsDe3gmtVifhXTRLpVKh1eqws3OipKTgkq8jAV4IIYQQ4jIZDFXY2Ogt3Q3RSeh0eqqrqy75fCmh6eB+OnSGlbuOkldUiaujDXcMC2RwuLeluyWEEEKIBozGGtRqK0t3Q3QSarUVRmPNJZ9v0QBfVVXFnDlzWLNmDUVFRYSEhPD0008zePDgC543YsQITp8+3eRr3bt3Z/PmzWZty5Yt49NPPyU9PZ1u3boxbdo0pk6d2mbvo738dOgMX3ybQlVd3VVuUSVffJsCICFeCCGE6GCkdEa01OX+XbFogJ8xYwabN29m2rRpdO/enVWrVvHQQw+xYMECoqOjmz3vb3/7G6WlpWZtGRkZvPvuuwwZMsSsfcmSJbzyyivEx8dz//33s3fvXl5//XUqKyt54IEH2uV9tZWVu46awnu9KoORlbuOSoAXQgghhLhKWSzAHzhwgPXr1zNz5kzuu+8+AG677TbGjh3LW2+9xcKFC5s9d9SoUY3aPvzwQwBuueUWU1tFRQWzZ89m5MiRzJkzB4BJkyZhNBp5//33mThxIg4ODm34rtpWblFls+2KoshP+kIIIYTo9B5//GEA3n//oyt6bmdmsQC/ceNGrK2tmThxoqnNxsaGCRMmMHv2bLKzs/H09Gzx9b755hv8/Pzo37+/qe2XX36hoKCAKVOmmB07depU1q1bx3fffceYMWMu/820EzdHm2ZD/P99uY+4GH8GBHtgpZZnkYUQQgjRtoYOHdii45YtW4uPT7d27o1oyGIBPjk5mZ49e2JnZ76IfWRkJIqikJyc3OIAn5SUxNGjR5k+fXqjdoC+ffuatYeHh6NWq0lKSurQAf6OYYFmNfAAWo2aQSGe/HG6kP+uOYSbo47YQf5cH+mD3kaeSRZCCCFE23j55dfNvl+6dDFZWZk88cQzZu3Ozi6XdZ/Zsz+wyLmdmcUSX05ODl5eXo3aPTw8AMjOzm7xtdatWwfAuHHjGt1Dq9Xi7Oxs1l7f1pp7WEJ9nXtTq9AYjQq/HTnLpoRTLNn2B2t2H2dYv26MGuCHq6POwj0XQgghRGcXF3ez2fc7d26jsLCgUfv5Kioq0OlankWsra0vqX+Xe25nZrEAX1FR0eSHbmNjA0BlZdOlI+czGo2sX7+esLAwAgMDW3SP+vu09B4NubnZt/qcyzHuRgfG3dinydfivByJG9KLw6fyWbXzCJsTTrFlTxrX9/PltmGBBPo5N3meEF2dh0fHfbZFiI5Exkrbyc5Wo9F07ZLW+mfvGr7PRx99iJKSYmbMeIk5c94hNTWZu+++l4cems533+1k9eqVHD6cQmFhIZ6eXowZcwv33vsAVlZWZtcAmDdvPgD79u3lscce5l//epPjx4+xatVyCgsLiYyM4oUXXsTfP6BNzgVYvvxrFi36itzcswQG9ubJJ5/mf/+bZ3bN899zW1Gr1Zc8Bi0W4HU6HdXV1Y3a60N1fZC/mISEBLKyskwPwp5/j6qqphfJr6ysbPE9GsrNLcFoVFp93uXy8HAgJ6e4yddc9BoeuCmEcYO7s2VvOt8dyGDn/nRCu7sQF+NP315uqOWBV3GVuNBYEUKcI2OlbRmNRgznrRx3uer3gsktqsStA+wFoyi1+afh+1QUhfz8fP7616cYPTqeuLib8fLyxmAwsm7dWnQ6PZMmTcXWVs++fXv56KN5FBeX8NhjTzV73Zqa2v//7LOPUautuOuuaRQXF7F48QL+/vcXmT//izY5d9Wq5bz99n/o168/kybdRWZmJs8//1ccHBzw8PA0XVOjUbf5ny3U/p1pbgyq1aoLThpbLMB7eHg0WcKSk5MD0OL693Xr1qFWq5usZffw8KC6upqCggKzMpqqqioKCgpa9ZBsZ+DurOeuUX24dWgPdiVmsHVvOu8uO4CPmy1xMQEMDvfCWiObTAghhBAdXWfaC+bs2RxmzHiZsWNvNWt/9dX/w8bmXCnNbbdN4M03/8mqVct46KFH0Wq1F7yuwWDg00+/QKOpjauOjk7MmfMWx44doVev3pd1bnV1NR9/PI/w8AjeffdD03G9e/fhjTdexcOjY2dEiwX4kJAQFixYQGlpqdmDrImJiabXL6aqqorNmzcTExPTZD19aGgoAAcPHmTo0KGm9oMHD2I0Gk2vdzW2OmtuuqY7sQP92ZOczaaEU3z+bQordx1lRH8/hvf3xcH2woNGCCGEEJfvh98z2X0gs9XnHc0oxFBj/hv/KoORzzYk891vGa2+3tBIH4ZE+LT6vJbQ6XTExzeeSG0Y3svKSqmqqiYqKpo1a1Zy8uQJ+vQJuuB1x4wZZwrWAFFR/QDIyDh90QB/sXNTUpIoLCzkz3++3ey42Nh45s5954LX7ggsFuDj4+P59NNPWbZsman8paqqipUrV9K/f39TIM/IyKC8vLxRfTvArl27KCoqMlv7vaFrr70WZ2dnFi1aZBbgFy9ejK2tLTfccEPbv7EORGOlZnBfb64N9yLlZD6b9qSxevdx1v98kiF9vYkd5I+Pm93FLySEEEKIK+r88H6xdkvy8PA0C8H1jh07yvz589i/f0+jDThLS0suel0vL/PfNDg4OAJQXHzx0q+LnXvmTO0PVX5+/mbHaTQafHza5wedtmSxAB8VFUV8fDxvvfUWOTk5BAQEsGrVKjIyMvjXv/5lOu6FF14gISGB1NTURtdYt24dWq2WuLi4Ju+h0+l48sknef3113nqqacYOnQoe/fuZe3atTz77LM4Ojq22/vrSFQqFaE9XAnt4crps6Vs2XOK3b+fYedvGfTr7U5cjD9B/s6yMZQQQgjRxoZEXNrM93Mf/tDkXjBujja8MLV/E2dYTsOZ9nrFxcU88cTD2Nra8+CD0/H19UOr1XL4cArz5r2H0XjxmnK1uumy3/q69/Y6tzOw6MLhs2bN4t1332XNmjUUFhYSHBzMRx99xIABAy56bklJCTt37uTGG2+84G6qU6dOxdramk8//ZRt27bh4+PDiy++yLRp09ryrXQavu523HdTKLffEMiO/els33+a3xadpYe3A3ExAQwMkY2hhBBCCEtrbi+YO4Y1rkjoiH79dR+FhYW88cab9Ot37geOzMzWl/+0B2/v2h+q0tPTiIqKNrUbDAYyMzMJDLxwiY6lWTTA29jY8MILL/DCCy80e8yCBQuabLe3t+fAgQMtus+kSZOYNGnSJfWxq3Ky03Lb9b24+dru/HjwDJv2pPG/tYdYvtOGUQP9uSGqm2wMJYQQQlhIw71gOsoqNK2hrpsMbDjjXV1dzapVyyzVJTMhIWE4OTmxdu0q4uJuNpUAbdmykeLiIgv37uIkoV3ltNZW3Bjtyw39upF45CybEtL4evsR1v5wnBuiuhE70F82hhJCCCEsYHC4d6cJ7OeLiIjEwcGRN954lQkTJqNSqdi0aQMdpYLF2tqaBx54mNmz3+Qvf/kzw4ePJDMzk2+/XYevr1+HLyuWWgkBgFqlIrqPBzOm9uflewcS0cuNLXvSeX7eT/xv7SFOnOn4P40KIYQQomNwcnJm1qzZuLm5M3/+PBYv/oqBA6/hz39+0tJdMxk/fjJ/+cuznDmTyQcfzCEx8Vf+/e93sLd3QKtt/V5BV5JK6SrV/FdIR9zIqb2cLSxn6950vkvMoKKqhmB/Z+KuCSAyUDaGEh2XbE4jRMvIWGlbZ86cxNu7u6W7IS6T0Whk7NhYhg0bzgsvvAS030ZOF/o702E3chIdn7uTnjtH9mHckJ58l5jB1n1pzF1+AG9XW0bH+HNduDdaa9kYSgghhBCdT2VlJTY25jPtGzeup6iokOjoiy+oYkkS4MVF2eo0xF8TwKiBfuxNzWZTQhpfbkxl1XfHGB7ty4j+fjjaycZQQgghhOg8Dhz4jXnz3uPGG0fg6OjE4cMprF+/ll69Ahk+fJSlu3dBEuBFi2ms1Fwb5s01oV4cTitg4y+nWPvDCTb8fIrr+noTFyMbQwkhhBCic+jWzRd3dw+WL/+aoqJCHB2diI8fw/Tpj2NtbW3p7l2QBHjRaiqViuAAF4IDXMjMLWXznjR+PHiG7xIziAx0Iy4mgJAA2RhKCCGEEB2Xr68fs2bNtnQ3LokEeHFZfNzsuDc+hNtv6MWO/afZvj+dNxf/SncvB+Ji/BkY4onGShY7EkIIIYRoKxLgRZtwtNVy69Ce3HRNAD8dOsPmPWl8tC6JZTuPElu3MZStTv66CSGEEEJcLklUok1pra0Y1s+X66O68fvRXDYlnGLpjnMbQ40a6Ie7k97S3RRCCCGE6LQkwIt2oVapiOrtTlRvd06eKWZTwim27k1n6950BoZ4EBcTQE8fR0t3UwghhBCi05EAL9pdd28HHh4XzoQbA9m6N51diadJSM4myM+JuJgAovq4y8ZQQgghhBAtJAFeXDGujjomjejNLUN68H1iBlv2pvHeyt/xctEzOiaA6/p6YyMbQwkhhBBCXJAEeHHF6W00jI4JYORAP/al5rAp4RQLNjXYGGqAH06yMZQQQgghRJNkfT9hMVZqNTGhXrw0bSAvTImmj58T3/x4guc+/JHPNiRz+myppbsohBBCiDayYcM6hg4dSGZmhqltwoRbeOONVy/p3Mu1f/9ehg4dyP79e9vsmleKzMALi2u4MdSZvDI270njh98z+f5AJhG93IiL8Se0u4tsDCWEEEJcQc8//zT79+9h3bot6PVNryD3zDOPc+jQ76xduxkbG5sr3MOW2bp1E3l5uUyaNMXSXWkzEuBFh+Ltasu0uGBuv74nO349zfZ96by15DcCPO0ZHeNPTKiXbAwlhBBCXAGxsXH8+OP37N69i9jY+Eav5+fnsW/fHkaPvumSw/uiRStQq9v33/Vt2zbzxx+HGwX4fv36s23bD1hbW7fr/duDJCHRITnYahk3pCdv/vk67rspBINR4eNvknnhvz/x7c8nKauotnQXhRBCiC7t+utvRK+3ZevWTU2+vn37Vmpqahg9unG4bymtVotGY5n5ZLVajY2NTbv/ANEeZAZedGjWGituiOrG0EgfDh7LY1PCKZbtPMraH09wfaQPsQP98XCWjaGEEEKItqbT6bj++mHs2LGVoqIiHB3N96CMZQ4AACAASURBVG/ZunUTbm5u+Pt35623/s2+fQlkZWWh0+no338gjz32FD4+3S54jwkTbiE6egAvvviqqe3YsaO8++6bHDz4O05OTtx66x24u3s0Ovf773eydu0qDh9OpaioEA8PT26++Rbuued+rKxqV7V7/PGH+e23/QAMHToQAG9vH5YvX8f+/Xt58snpzJ37X/r3H2i67rZtm/nqq885efIEtrZ2XH/9DTzyyBM4Ozubjnn88YcpKSnh739/nXfemUVy8iEcHByZOPFOpk69t3Uf9CWQAC86BbVKRWSgG5GBbpzKKmZTQho79p9m2750BgR7EhfjT2A3J0t3UwghhGgzCWf2s/boRvIrC3CxcWZcYDwx3v2vaB9iY+PZvPlbdu7cxrhxt5vaz5zJ5ODBA0yYcCfJyYc4ePAAo0bF4eHhSWZmBqtXr+CJJx7hq6+WodPpWny/3NyzPPnkdIxGI3fffS86nZ61a1c1WaKzYcM36PW2TJ48FVtbPfv27eXjj/9LaWkpjz32FAD33vsA5eXlZGVl8sQTzwCg19s2e/8NG9bxz3++Rnh4BI8++iTZ2VmsWPE1hw4dZP78L836UVRUyF//+iTDh49k5MjR7NixlXnz3qNXr94MHjykxe/5UkiAF51OgJcDD90Sxvhhvdi2L52dv2WwNyWb3n5OxA0KILqPO2q1PPAqhBCi80o4s59FKSuoNtaWjOZXFrAoZQXAFQ3xgwZdg7OzC1u3bjIL8Fu3bkJRFGJj4wgM7M3w4aPMzhsy5AamT7+fnTu3ER8/psX3W7jwCwoLC/j44wUEB4cAcNNNY7nrrtsbHfvqq/+Hjc25Hw5uu20Cb775T1atWsZDDz2KVqtl0KBrWblyGYWFBcTF3XzBexsMBubNe4/evYN4773/odXWLmkdFhbGyy/PZN26VUyYcKfp+OzsLF555f9MzweMHXsrEyaMZf36NRLghWiOq6OOicN7M/a6Huw+kMmWvWl8sOp3PF30xA70Z2iEDzZa2RhKCCGE5fySuY+fMve0+rzjhacwKAaztmpjNQuTl/NjRkKrrzfYZxDX+Axo9XkajYYRI0axevUKzp49i7u7OwBbt27Gz8+fsLC+ZscbDAZKS0vw8/PH3t6Bw4dTWhXgf/rpByIiokzhHcDFxYXY2JtYtWqZ2bENw3tZWSlVVdVERUWzZs1KTp48QZ8+Qa16rykpSeTn55nCf72RI2OZO3c2P/74g1mAt7e3Z9SoONP31tbWhIaGk5FxulX3vRQS4EWnp7fREDvInxEDfNl/+CybEk6xcMthVn9/jOH9fRnZ3w8n+465tJUQQgjRlPPD+8Xa21NsbDwrVy5j+/bNTJo0hRMnjnPkyGHuv/8hACorK1iw4HM2bFhHTk42iqKYzi0pKWnVvbKyzhAREdWoPSCge6O2Y8eOMn/+PPbv30NpqfneMaWlrbsv1JYFNXUvtVqNn58/WVmZZu2enl6Nlrh2cHDk6NEjrb53a0mAF12GlVrNoBBPBgZ7cOR0IZsS0lj/40k2/nKKa8O8GR3jj5+HvaW7KYQQ4ipyjc+AS5r5fumHf5JfWdCo3cXGmb/0n94WXWuxiIgofHx82bJlI5MmTWHLlo0AptKR2bPfZMOGdUyceBd9+0Zgb28PqHj11b+Zhfm2VFxczBNPPIytrT0PPjgdX18/tFothw+nMG/eexiNxna5b0NqddO/5W+v99yQBHjR5ahUKvr4OdPHz5ms/DK27Elj94FMdv+eSd+ersTFBBDWQzaGEkII0XGNC4w3q4EHsFZbMy7w0pdsvByjRo1mwYLPSE9PY9u2zQQHh5pmquvr3J944mnT8ZWVla2efQfw8vImPT2tUfupUyfNvv/1130UFhbyxhtv0q/fuWcCmt6ptWX/3nt7+5ju1fCaiqKQnp5Gz56BLbrOldD5Fr4UohW8XGy5e3Qwbz02hNtv6EVadglvf/0br3y6hx9+z8RQ0/4/oQshhBCtFePdnykh43GxqV260MXGmSkh46/4KjT1Ro++CYD3359Nenqa2drvTc1Er1jxNTU1Na2+z+DBQ/j990RSU1NMbfn5+WzZ8q3ZcfVrtzec7a6urm5UJw+g1+tb9MNESEgYLi6urF69nOrqcz84bd++lZycbK67rn0fTG0Ni87AV1VVMWfOHNasWUNRUREhISE8/fTTDB48uEXnr1u3ji+++IIjR46g1WoJCgri+eefJzIyEoD09HRGjhzZ5Lnz58/nhhtuaLP30l7ql5AqqCzA2UJLSHUF9nprbrmuB/ExAfycdIbNe9L4ZH0yy3cdZdQAP26M9sVO1/l2YhNCCNF1xXj37zD/5vfs2YvevYPYvfs71Go1I0eee3jzuuuGsmnTBuzs7OnRoyeHDv3O3r0JODm1fnnnKVPuZdOmDTzzzGNMmHAnNjY61q5dhZeXDyUlf5iOi4iIxMHBkTfeeJUJEyajUqnYtGkDTVWvBAeHsHnzt7z33juEhISh19sydGjjDKjRaHj00Sf45z9f44knHmHUqNFkZ2exfPnX9OoVyC23NF4Jx1IsGuBnzJjB5s2bmTZtGt27d2fVqlU89NBDLFiwgOjo6AueO3v2bD7++GPGjRvH5MmTKSsrIyUlhZycnEbHjhs3jqFDh5q1hYSENDquo+koS0h1JdYaNddHdmNohA+HjtduDLVi1zHW/XiC6yO6ETvID0+X5teHFUIIIa5Wo0fHc+TIYaKjB5hWowF46qlnUavVbNnyLZWVVURERPHuux/wzDNPtPoe7u7uzJ37P2bPnsWCBZ+bbeT073//w3Sck5Mzs2bN5v3332X+/Hk4ODgyevRNDBwYwzPPPG52zVtvHc/hwyls2PANX3+9CG9vnyYDPMDNN9+CVqtl4cIv+OCDOdjZ2REXdxMPP/x4k2vRW4pKuRKV9k04cOAAEydOZObMmdx3331Abb3U2LFj8fT0ZOHChc2eu3//fqZMmcJ7771HbGxss8fVz8A3vMflys0twWi8Mh9Zcw+wOGjt+eeQl1CrpAKqLaRll7A54RQ/J2VhVBT6B3kQFxNAb1/ZGKoz8vBwICen2NLdEKLDk7HSts6cOYm3d+OVUkTnp9GoMRjavuT2Qn9n1GoVbm7NL7xhsRn4jRs3Ym1tzcSJE01tNjY2TJgwgdmzZ5OdnY2np2eT53755ZdEREQQGxuL0WikvLwcOzu7C96vrKwMjUZjtq5nR9dUeAcorirhhe9fI9Q1iDC3YMLcgnHUOlzh3nUd/p72PDg2jDuGBbJ9fzo79p9mX2oOgb6OxA0KoH+Qh2wMJYQQQogOw2IBPjk5mZ49ezYK3pGRkSiKQnJycrMB/qeffmLMmDG88847LFiwgLKyMnx9ffnLX/7CuHHjGh0/Z84c/vWvf6FSqYiKiuLZZ59l0KBB7fK+2pKLjXOTId7O2pa+bqEk5aWyLzsRAH8HX8Jdgwl1C6anYwBWzSxtJJrn4mDD+GGBjBnc3bQx1IerD+LhrKvdGCrSB51WFm4SQgghhGVZLI3k5OTg5eXVqN3DwwOA7OzsJs8rLCykoKCA9evXY2VlxbPPPouzszMLFy7kueeeQ6/Xm8pq1Go1Q4cOJTY2Fk9PT06ePMknn3zC/fffz+eff87AgQPb7w22geaWkJrQZxwx3v0xKkbSSzJIyk0lKTeVzad2svHkdvQaPSGufQh3rZ2dd7JxtOC76Hx0Wg2jBvozor8f+w/nsGnPKRZt/YM1u48zrJ8vIwf44eLQcerghBBCCHF1sVgN/KhRo+jduzf//e9/zdrT0tIYNWoUL7/8MnfffXej8zIzM7nxxhsBWLp0KVFRtbt1VVVVERsbi4uLC6tXr272vllZWYwZM4bevXuzZMmStntD7eT7kwksPrCG3LI83GxduSvyVq7vHtPksSVVpfyelcKvmYdIzEwiv6IQgB7OfvTzCaefdzhB7r3QyOx8q6WcyGPVriP8/HsmarWKG6L9uG1YID27SZ28EEIIOHQoiW7dpAZetFxGxknCw8Mu6VyLzcDrdDqzNTbrVVZWAjT7pG99u5+fnym8A2i1WuLi4vjyyy8pLS1ttibey8uLMWPGsHTpUsrLy9Hr9a3q95V8iBUgxDaU164NNXvY6EIPHfXWBdG7ZxATetxGekkmSbkpJOWlsjZlC6uTN6Gz0tXOztfVzjvbSABtCTc7a/50cyjjrutRuzFUYgbb96YR3sOFuJgAwnu6ysZQHYQ8mCdEy8hYaVtGo7FdHnQUltdeD7EajcZmx2CHfYjVw8OjyTKZ+mUgm6t/d3Z2RqvVmi1fVM/d3R1FUSgpKbngQ60+Pj4YjUaKiopaHeA7C5VKhb9DN/wduhHXYwTlhnJS8o7UBfrD/JbzOwDd7LwJdwshzC2YQKceUjt/EZ7OeqbGBnHb9T3Z+etptu5L552lifh62DF6kD/XhnljrZHVgYQQQgjRfiwW4ENCQliwYEGj2fLExETT601Rq9WEhoaSlZXV6LUzZ85gZWV10Y0D0tLSWnRcV6LX6In2jCDaMwJFUcgoPUNSbiqHclPYlvYdW07tRGdlQ3CD2nkXnbOlu91h2emsGTO4B3ExAfySlMWmhFN8tiGFlbuOMWKAH8OjfbHXy8ZQQgghhGh7Fgvw8fHxfPrppyxbtsy0RntVVRUrV66kf//+pgdcMzIyKC8vJzAw0Ozc//znP/zwww8MGVK7rW1JSQnffvst0dHR6HQ6APLy8nB1dTW778mTJ1m/fj0DBw40HXe1UalU+Nr74GvvQ2z3Gyk3VJCaXzs7fyg3lcScgwD42HkR5hZMuGsIgc490KhlBZbzaazUDInw4bq+3iSdyGdTwilWfXeM9T+dYGiED7GD/PGSjaGEEOKqoCiKlFOKFrncR1At9hArwFNPPcW2bdu49957CQgIYNWqVRw8eJAvvviCAQMGAHDPPfeQkJBAamqq6bzy8nLuuOMOsrKyuO+++3B0dGTFihUcP37c7NyZM2eSlpbGtddei6enJ6dOnWLJkiUYDAYWLlxIeHh4q/t8pWvg612pWkVFUcgszSIpL5VDuakcLThOjVKDjZWWYJc+hLkFEeYagpvepd370lml55SwOSGNn5POUFOjEB3kQVyMP719neQ/7FeA1PUK0TIyVtpWTs5pnJzc0WpllbKupj1q4KuqKiksPIuHh2+Tr1+sBt6iAb6yspJ3332XdevWUVhYSHBwMM888wzXXXed6ZimAjzU1srPmjWLXbt2UVFRQXh4OM8884zZ+u7ffPMNS5Ys4ciRIxQXF+Po6EhMTAyPP/44ffr0uaQ+d/UAf74KQwWp+UdJyqtdqjKvIh8Ab1vP2tl5txACnXtiLbPzjRSWVLKtbmOo0goDvbo5EhcTQP8gd6zUUiffXiSUCNEyMlbaVnl5KcXF+Tg7e2BtrZUJmy6kLQO8oihUV1dRUJCDg4MLen3Tz2x26ADfGV1tAb4hRVHIKsvmUN2680cKjmFQatCqrQly6V23sk0I7nrXi1/sKlJZVcMPBzPZvCeN7Pxy3J3ObQylt5EffNpaRxgrQnQGMlbaXnl5KSUlBdTUGCzdFdGG1Go1RmPbzcBbWWmwt3duNrzX3lMCfJu6mgP8+SoMlfxRcLTuYdhUcivyAPCy9TDVzvd27om1lTzMCWA0Kvx25CwbE05xJL0QvY2GG/t1Y9RAf9kYqg11xLEiREckY0WIC0s4s5+1RzdSUFmAs40z4wLjifHuf0XuLQG+jUmAb5qiKGSX5XCortTmj4JjGIwGrNXWBLkEmgK9h62bpbvaIRzNKGRTQhr7UrNRq1TEhHoRF+NPgJeDpbvW6XX0sSJERyFjRYjGFEWh2ljNjxl7WHV0PQbjud+mWKutmRIy/oqEeAnwbUwCfMtU1VRxuK52/lBuKmfLcwHw1LsTVreJVB/nQLRX+ex8TkE5W/am8X1iJpXVNYR2r90YKqKXbAx1qTrbWBHCUmSsiK5KURQqaiooq66gzFBOuaGMsupyygwVlBnKKG/wdZmh3Oz78upyDEpNs9d2sXHm/4b8rd3fgwT4NiYB/tJkl+WQlHuYQ3kp/JF/lGqjAWu1hj7OdbPzbsF42npYupsWU1ZRza7fMti6L5384kq6udduDDU43AtrjWyu1RqdfawIcaXIWBEdWY2xhnJDfQAvrwvgZZQZKuoC97n/lTfxmkLzWU2FCluNHr21HluNvtHXtho9a4592+z5H4yY1R5v2YwE+DYmAf7yVdVU80fBsdpdYXNTyS4/C4C73o0w19owH+QSiNZKa+GeXnmGGiMJyVlsSkgjLbsER1tr08ZQDrZX3+dxKbrSWBGiPclYEe2tuqb6XAA3hfCGobvx12XVtcdX1FRe8NoalVVd6LatC+C6uvBti61Gd+41a33t93XH2VrrsbHSolZdeDW4l374J/mVBY3aZQa+k5IA3/ZyynLrlqlMITX/KNXGajRqDX2ce9WW27gG42XrcVWVlCiKQsrJfDYmpPH7sVy0GjXXRfgwepA/3q6yMdSFdOWxIkRbkrEiLkZRFCprKutCeAVl1WV1QbuCctPX5ZRVV9SWqTQI4GWGcqqNF16NR2ulPTcDXheu60O2vsFsuNn3dcHcWq1p11yQcGY/i1JWUG2sNrVJDXwnJgG+fVXXVHOk4DiH8mpn57PKcgBw07kQ5hZSNzvfG5uraHb+9NlSNiec4qdDtRtDRfV2Jy7GnyB/56vqh5qWulrGihCXS8bK1cGoGOvCd4OZ8Eaz3mWmcpX6UpX6741K88snqlCh0+gaBGvzoG0eus8L6Ro9VuqOXSIqq9B0IRLgr6yz5Xkk5aaSlJdCat4RqozVaFRW9K6fnXcLxtvW86oIsoWlVWzfl86OX09TUl5NTx8H4mICGBDsIRtDNXC1jhUhWkvGSudhMBoazW6f/7V5rfi578sNFRe8tlqlNpvZ1psCeV1pikZneu1cqUrt1zqNzUVLUboCS4wVCfBtTAK85VQbDRwtOF677nxeKmdKswBw1bkQ5hpEmFsIwS6B6DQ6C/e0fVVW1/DjwTNsTjhFVn45bo46Ygf6cX1UN9kYChkrQrSUjJUrR1EUqozVphKUhuUo5qUp54XwupBe1aCMoylatbXZ7Pb5M91mD2ham4d0rdr6qpgEuxwS4LsACfAdR255fl3tfCqp+X9QWVOFlcqKQOeehLkGEe4Wgo+dV5f9D5NRUUj84yybEk5xOL0QvY0Vw6J8GTXQD1fHrv1DzIXIWBGiZWSstI5RMVJhqKwL2mWU1y1RaCo3qW6iHKVu+cJyQwU1F1iaEECv0ZnVfZuH7ubLUfQaPdZqmbxpTxLguwAJ8B2TwWjgWOEJDuXWBvqM0jNA7dPiYW71s/O90XfR2fnjmUVsSjjF3pQcVCoYFOJJXEwA3b2vvo2hZKwI0TJX41ipMdY0Wu3kguUoDb6vMFRccGnC+lKU2tlt27pw3VQ5im2jBzf1Gt1VUYrSWUmA7wIkwHcO+RUFplKb1Lw/qKipRK1SE+jUo27d+RC62Xl3udn5s4XlbN2bzneJGVRU1RAS4MzomAAiA91Qd7H32hwZK0K0TGccK7W7ZBpMM9vnl5xcrCa8qqbqgte3Vmsu+uCl+Wop58pRbKxsuty/KaKWBPguQAJ852MwGjheeLJ2dj4vldMlmQA42ziZaudDXHuj1+gt3NO2U1Zh4LvEDLbsTSO/uBIfN1tGD/Lnur7eXX5jKBkrQrSMpcZK7S6Zlc2E7oblKPW7ZDYoVbnILpkAOiubC4bu80tTGq6cYn2V7w4umiYBvguQAN/5FVQW1q5sk5tKSv4flBsqUKvU9HTsTrhbMGFuIfjZ+3SJmRRDjZG9KdlsSkjjZFYxDrbWjOjvx/D+vjh20Y2hZKwIcWFtsTRejbGG8pqKpktPmtwl0/zrFu2S2WD1E33dZjznVkJp8H2D+nC9RtfhlyYUnY8E+C5AAnzXUmOs4XjRKQ7V7QqbXpIBgJPWgdC6TaRCXftga925N09SFIXUUwVsSjhF4tFcrDVqruvrzehB/vi42Vm6e21KxooQzWt6cxoNsQE30t3Rvx12yWx6m/pzO2jq6gJ4/S6ZOmysro6lCUXnIQG+C5AA37UVVhaRlHeYpNwUkvP+oNxQjlqlpodjQN3sfDB+9t069T8uGWdL2bwnjR8PnsFQYyQq0I34awK6zMZQMlaEOKfcUEF2WQ7ZZWfJKsth26ldF12SsF6zu2S2YIUUa1maUHQhEuC7AAnwV48aYw0nitJIyk0hKS+VU8WnAXDQ2hPmWhvmQ12DsOuks/NFpVVs35/O9v21G0N193YgLsafgcGeaKw67w8oMlbE1abGWMPZ8lyyy2tDesPAXlR1biyoUF2wdOXZAY83qAnXoZGlCYUAJMB3CRLgr15FVcUk5x7mUG4KKXl/UGooQ4XKbHbe38G3083OV1XX8OOhM2xOSONMXhmujjaMGuDPDVHdsNV1vn/AZayIrkhRFIqqik0BPasupGeX5XC2Is9su3t7azs8bT3wtHXHy9YDT1sPvGw9cNe58trPb5JfWdDo+i42zvzfkL9dybckRKchAb4LkAAvoHZDD9PsfO5hThWno6Bgb21HqGsw4XWz8/bazlNfblQUDhzNZXPCKVJOFaDTWnFDVDdiB/rj5tR51s+XsSI6swpDhSmYZ5XlkF1+1jSj3rDu3FqtqQ3pendTQPe0rf36Qr8VbLoG3popIeNb/SCrEFcLCfBdgAR40ZTiqhKS82pn55PzDlNaXTs7393Rn7C6h2G7O/p1mtn5E2eK2JyQRkJyNgADQzyIiwmgp4+jhXt2cTJWREdXY6whtyLPNIt+ruwlh8LzSl5cdc51s+nnQrqXrQfONk6X/N+TtliFRoiriQT4LkACvLgYo2LkZFE6SXm1S1WeLEpDQcHO2pZQ1yDC3UIIdQ3CQdv8wOwocgsr2Lovje8SMyivrCHI35n4mAAie3fcjaFkrIiOoLbkpYTssuxzIb28NrDnlOealbzYWdvWhnO9edmLh96tXdcll7EiRMtIgO8CJMCL1iqpKq2bnU8lOS+VkupSVKjwd/A1rTvfw9G/Q8/Ol1fWbgy1dW8auUWVeLue2xhKa92x1lyWsSKupApDpSmYm9emn6WipsJ0nEatMZW7NAzpnrbu2FtbptROxooQLSMBvguQAC8uh1ExklZ8mqTcVA7lpnKi6FTt7LzGlhDXPrWz825BOGodLN3VJtUYjexNyWFTwilOnCnGXm/NiP6+jOjvh6Ndx9gYSsaKaGu1JS/5pjKXhqUvhVVFpuNUqHDROZvVo3vVzaq76Jw73A/pMlaEaBkJ8F2ABHjRlkqry0jOO1y7M2xeKsVVJQC1s/Ou52bnO9rOgoqicDitgE0JaSQeOYuVlZrr+noxelAA3dwt++CujBVxKRRFobi6hKzSc6Uu9UH9bHkuNUqN6Vg7ja1p9rxhbbqH3h1tO5a8tDUZK0K0jAT4LkACvGgvRsVIekmGaXb+eOFJFBT0Gj2hrn0IcwshzDUIJ5uO9SBpZm4pW/ak8cPBM1QbjEQGuhE3yJ+Q7i4W2chFxoq4kMqaqroSl2yzkJ5dnkO5wbzkxUPv1qDUxQOvusBuqZKXtiZjRYiWkQB/nqqqKubMmcOaNWsoKioiJCSEp59+msGDB7fo/HXr1vHFF19w5MgRtFotQUFBPP/880RGRpqOMRqNfPLJJyxevJicnBx69OjBo48+ys0333xJfZYAL66UsuoykvP+ICkvleTcVNPqFH723QhzCybcLYSejgEdZna+qKyKnftPs31/OkVl1QR42RM3KIBBoVd2YygZK6LGWENeRQFZZdkNNjeqrVEvqCw0O9bFxtmsHr3+a9cOWPLS1mSsCNEyEuDP88wzz7B582amTZtG9+7dWbVqFQcPHmTBggVER0df8NzZs2fz8ccfM27cOPr3709ZWRkpKSmMGjWKkSNHmo57++23+eijj5g8eTJ9+/Zl27Zt7Ny5kzlz5hAfH9/qPkuAF5agKArpJZkk5abUzs4XncSoGNFrdAS79DFtJOVs42TprlJtqOGnQ1lsSjhFZm4ZLg42jBrox7Cobtjq2r+8QMbK1UFRFEqqSxvtPJpdlkPOeSUveo0er/PWSveqW+VFa9Uxnt2wBBkrQrSMBPgGDhw4wMSJE5k5cyb33XcfAJWVlYwdOxZPT08WLlzY7Ln79+9nypQpvPfee8TGxjZ7XFZWFiNHjuSuu+7ixRdfBGr/o3/33XeTmZnJ1q1bUatbN8MiAV50BOWGclLyjpgCff2DdL72PoTVbSTVy6mHRWfnjYrCwWO5bEpII/lkPjZaK26I7EbsQD/cnfXtdl8ZK11LVV3Ji9ma6XU16uWGctNxGpUV7vUz6OdtbmRvbWeRcq6OTsaKEC3TEQO8xfZJ37hxI9bW1kycONHUZmNjw4QJE5g9ezbZ2dl4eno2ee6XX35JREQEsbGxGI1GysvLsbNrXJO4detWqqurmTJliqlNpVJx11138de//pUDBw7Qr1+/tn9zQrQzvUZPtGcE0Z4RKIpCRukZDuWmkJSbyra079hyaic6KxuCXfvUPQwbjIvO+Yr2Ua1SERnoTmSgOyfPFLN5zym2709n6740BgZ7EhcTQK9uHaueX1iGUTGSV5FvVupS/3V+ZYHZsS42znjaujPIq59ZbbqrzqXLl7wIIUQ9iwX45ORkevbs2Sh4R0ZGoigKycnJzQb4n376iTFjxvDOO++wYMECysrK8PX15S9/+Qvjxo0zu4e9vT09e/ZsdA+ApKQkCfCi01OpVPja++Br78Po7sMpN1SQmn9udj4x5yAA3ey862rna2fnNeorN/y7ezvw0C3hjB8WyLZ96ez8LYM9Kdn08XMiLiaAfr3dUatlhrQrqy95OX/n0azys5wtO4vBrORFPe62aQAAIABJREFUh6etB31ceuGp98DLrn5W3f2qLnkRQoh6FgvwOTk5eHl5NWr38PAAIDs7u8nzCgsLKSgoYP369VhZWfHss8/i7OzMwoULee6559Dr9aaympycHNzd3Vt9DyE6M71GRz+PvvTz6IuiKGSWZpGUV7uyzY603Ww9tQsbKy3BLn1Mgd5V53JF+ubqqGPi8N6Mva4Huw9ksnlPGu+v/B1PFz2jB/kzJMIHmw62MZRonaqaKnLKc00hveGselmDkhcrlRUeejc8bT2IcAs1q02XkhchhLgwiwX4iooKrK0bP9BmY2MD1NbDN6WsrAyAgoICli5dSlRUFACxsbHExsbywQcfmAJ8RUUFWm3j2ZqL3eNCLlSP1N48PDrm5j6iY/PEkaiefYCxlFdXcDA7lV8zD/Fb5iEOnD0EgJ+jD/28w+jnE06oR+923b693hQ/FybHhfDj75ms3nWErzYfZs3u49x8XU/GDOmJi6Pukq8tY6V9GY1GzpblkVGcTUbxGTKLs8koziKzOJuzZXlmx7rpXfBx8CTIYxA+Dp50c/TCx8ELD1vXDrOC0tVMxooQLdPRxorFArxOp6O6urpRe32org/Z56tv9/PzM4V3AK1WS1xcHF9++SWlpaXY2dmh0+moqqpq9T0uRB5iFZ1dD20venTvxW0BY8kqy+ZQbipJuals/GMn3xzehtZKS7BLIGGuIYS7BeOmd23X/oT4OvLCXdH8kV7IpoRTLN16mBU7/uDacG/iBvnj69G6H5plrLSdkqpSsstz6jY3Ml/lxWA0mI7TWenwsvWgp0MPrvUaWDeb7omnrTs2TZW8lENeedkVfCeiKTJWhGgZeYi1AQ8PjyZLWHJycgCarX93dnZGq9U2WRrj7u5eW2dZUoKdnR0eHh7s3bu31fcQ4mqgUqnwtvPC286LkQE3UGGo5I+Co3WBPoXfzyYD4GXrUVtq4xpCb+ee7TI7r1KpCPJ3Jsjfmay8MjbvTeOHA5nsPpBJ316uxMUEEGahjaG6uqqaanLOWyu9flnGUsO5kG2lssJd74anrTvhbiF1a6bXhnQHa3v5sxFCiCvIYgE+JCSEBQsWmGbL6yUmJppeb4parSY0NJSsrKxGr505cwYrKyucnGrXwg4NDWXZsmUcP37c7EHW+nuEhoa22fsRorPTaWyIcA8jwj0MRVHILsvhUF7t7Pz3p39mR9putGprglwC63aFDcbD1q3N++Hlass9o4O5/fpe7Pj1NNv2pfP2kt/w97Rn9CB/rgnzuqIbQ3UFRsVIfkWB2TKM9bPq+RUFKJz7raKzjROeeneivSLxqluO0dPWAzedi5S8CCFEB2GxdeATExOZNGmS2TrwVVVVjB07Fjc3NxYvXgxARkYG5eXlBAYGms79f/buPKzJM+0b/zeBEBZBtrAGENkF2YI7Lii2qGitVWttq7aO47y1TzvO9H3UpzNtx/46nbp07GPb6dTqzOiLVVFwmbZWAbdaBQEFFdwQlRCWIAKyB8jvD2umFJREwTvA93McHoe57u2Mh2dycnHe171lyxZ89NFH2LJlC8aMGQMAqK2txeTJkzF48GDdGvKlpaWIjY3tdB14lUqF1NRUrgNPpIfm1mZcuVOguxm2ouE2AMDJwhFDHAIwxCEQfraDYdYDs/OaljacvliKQ2eKUFxRB9sBZpikkGNChDusOnkwVH/Olc5WeSmvr0B5Q8UvWl6kHZ48eu/BRo4wNzW8tZB6p/6cK0SGMMYWGkGfxPrmm28iNTUVCxcuhKenp+5JrP/617+gUCgAAC+//DIyMjJw+fJl3XENDQ2YNWsWysrKsGjRItjY2GDPnj0oLCxsdywArFmzBlu2bMHcuXMxdOhQpKSk4OjRo/jrX/+KqVOnGhwzC3gi3Jud/6l3/mpVATRtLZCITeFn56N7kJSTpaxbr6nVanGhsBLfZ9xC3o07kEpMMDbUFZOHeUBma4FTF0uRdKwAlTVNsLeRYtZ4H4wKdunWGIyBplUDdcPtdiu83J9Vr9P8p+VFLBL/tMrLT6u7WMh0s+k2Zmx5IX6vEOmLBfwvNDU1YcOGDThw4ACqq6sREBCA3/3udxg9erRun84KeOBeH/uaNWtw7NgxNDY2Ijg4GL/73e8wbNiwdvu1tbVh06ZN2LlzJ8rLy+Ht7Y2lS5ciPj7+kWJmAU/UXnOrBlerriPvpwdJlTdUAAAcLRwQ7BCAIfYB8Lfz6db1u2+V3cWhM0VIzytDm1aLQc7WKFLXoqX1P7lpZirGwimBvbKIv9fyUn2v1eUXvemVv2h5GWhm024Jxvuz6g7mXOWFHo7fK0T6YQHfB7CAJ3o4df1tXKy8V8xfuVMATZsGpmJT+NkO/ulm2Huz890xA3znbhNSs5T47vRNdJaVDjZSrH1tzGNfp6fUaep1bS4/Xzdd3VABzc9aXqQmZrpWl3uz6Y5w+unhRuamj77cJvVv/F4h0g8L+D6ABTyR/jStGlyrKtQV9GX191aAcjC3vzc77xAAfzvfzpcaNMCrf0l74LYtKyc+1rkfl6atBeqf+tDL69Qoa/hPb3qtpk63n1gkhqOFPZwsOvam25hZs+WFuh2/V4j0Y4wFvGCr0BBR3ycxkSDIwR9BDv6AH1DRUIm825eRV3kJp0sycbz4FExFJvC9PzvvEABnSyeDi1UHGylu13R8MJu5mQkamlpgIe3Zj7o2bRuqmqo7zKSX11egsvHOL1perOFkKUOYLPhnbS8yOLLlhYiI9MQZeANxBp6oe2jaWlBQVYiLP/XOl9bfey6EvbndvZVt7AMQYOer16oopy6W4l/fXUJzS5tuTCwC2rTAQCszzJ7gg1EhLhA/5ix2vaYeZT/rRy9rqNDNpmva/vNgOqmJ2b12F4tfrPJi6QgLtryQkeD3CpF+jHEGngW8gVjAE/WM2w13kPfTuvOX71xFU2szTEQm8LH11t0M62rl/MDZ+c5WoXG2s8T2lCu4rqqBt6sN5k/2g4/bwIfGoWlrQUVnq7zUqzu2vJjb624gvVek3/v7QDMbtryQ0eP3CpF+WMD3ASzgiXpeS1sLCqpu6Ap6VV0pAMBOaoshDv4Y4hCIADvfdrPZGaXZ2F9wEFVNVbCV2mKGTxyGu0SiTavF6YulSDxagOraZowKdsGs8d4QmzW1W+GlrEGN8jo1bv+i5cXabMC9WXQLGZyt/jOr7mBhD1MxuxCp9+L3CpF+WMD3ASzgiZ68O41VyLt9GRcrL+Ny5VU0tjZBLBLDZ+AgBDsEok3bhu9upLZrY5GIJZjtNx1yazeU11eguKYMucU3UVanBqT1EJm06vY1MzH72VNH2y/JaGFqIcRbJupx/F4h0g8L+D6ABTyRsFraWnC9+uZPN8NeRnFtiV7HiSCCg4U97CT2qCg3QVmJGDamdnh2+FCMDhhk8FOZiXo7fq8Q6YcFfB/AAp7IuFQ1VePtkx88cPuvhy6Es6UjHC0c2rW8XCysxNepV6GqqEPwIDvMi/WHu6PVkwiZyCjwe4VIP8ZYwHPKiYh6NVvpQNhJbTvdZie1RZgsGC5Wzh361YO97fHeK8MwP9YPhSV38e7mDGw/fAV1jZpOz0VERGQsWMATUa83wycOErGk3ZhELMEMn7iHHmdqIkZslAc+XDoS48PdkJqtxKq/n8aRs8WC/KaNiIhIH2yhMRBbaIiM04NWoTHErbK7+DrlKi4XVUEuG4D5sX4I9LLroYiJhMXvFSL9GGMLDQt4A7GAJzJuj5srWq0WWZfV2Jl2DbdrGhEVIMPcib5wHMjVaKhv4fcKkX6MsYDnIsZERD8jEokQFeiEUB8HHMy4hW9P3UROwW3EDffE1JFekJqZCB0iERH1cyzgiYg6YSYxwYwx3oge6orEowU48OMN/HC+BHNjfDE8yIlPWiUiIsHwJlYiooewtzHH0hnBWPliJGwszfD3/RfxYUI2bpay9YCIiITBAp6ISA/+Hrb448IoLJoSiLLKeqz+5xn887t81NQ1Cx0aERH1M2yhISLSk1gswrgwN0QFOGH/yUKkZilx5lI5ZozxxiSFHKYmnBMhIqKex28bIiIDWZqbYt4kP6xePBy+7rbYmXYN72zOQG7BbaFDIyKifoAFPBHRI3J1sMLyuWF4c3YotFotNiTmYENiDkor64UOjYiI+jC20BARPaYwX0cEe9sjJVOJ/ScL8cev0jE5ygPTxwyChZQfs0RE1L34zUJE1A1MTcSIG+GJUSEu2HOsAN9n3MKPF0rw3HgfjAl1hZjLThIRUTdhCw0RUTcaaGWGV6cG4Q8Lo+BkZ4l/fHcJ7/8rE9eU1UKHRkREfQQLeCKiHuDtaoNVL0Xi19OHoKauGX/+f1n4cv9FVNY0Ch0aERH1cmyhISLqISKRCCODXRDu54hvT9/EwfQiZF9VY9qoQYgb7gGJqYnQIRIRUS/EAp6IqIeZm5li1jgfjA11w660a0g+fh0nclR4fqIvIv1lELE/noiIDMAWGiKiJ0Rma4Fls4bi/84Lh9TMBJ8lX8C6HeegLK8VOjQiIupFRFqtVivUxZubm/HJJ59g3759qKmpQWBgIJYvX45Ro0Y99LiNGzfi008/7TDu6OiIkydPthsLCAjo9BzvvfceXnjhBYNjvn27Fm1tT/6fTCazhlp994lfl6i36S250trWhmPnVEg+fh31TS2YEOGOZ8cOxgALidChUT/RW3KFSGhC5IpYLIKDw4AHbhe0hWblypU4dOgQFixYAC8vLyQnJ2PJkiXYtm0bIiIiujx+9erVMDc3173++d9/Ljo6GjNmzGg3FhYW9njBExE9BhOxGBMj5Rge5Ix9Jwpx5GwxMvLKMHPsYEyIcIOJmL8gJSKizglWwOfm5uKbb77BqlWrsGjRIgDAzJkzER8fj3Xr1iEhIaHLc0yZMgU2NjZd7jd48GA888wzjxsyEVG3G2AhwYtP+WN8hBu+TrmKhMNXcPRcMeZP8kPQIHuhwyMiIiMk2BTPwYMHIZFIMGfOHN2YVCrF7NmzkZWVhfLy8i7PodVqUVtbC326gBobG9HU1PRYMRMR9RS5bADemheOZc8ORVNzK9buOIdPk85DXdUgdGhERGRkBCvg8/Pz4e3tDSsrq3bjoaGh0Gq1yM/P7/IcEyZMgEKhgEKhwKpVq1BVVdXpfrt370Z4eDhCQ0Mxffp0HD58uFveAxFRdxKJRFAEyPDBkhGYNW4wLhTextub0rHnWAEam1uEDo+IiIyEYC00arUazs7OHcZlMhkAPHQG3sbGBi+//DLCwsIgkUhw+vRp7Ny5E3l5eUhMTISZmZlu34iICEydOhVyuRwlJSXYunUrXn/9daxfvx7x8fHd/8aIiB6TxNQE8aMHYcxQV+w+eg3fnLqJk+dLMGeCL0YGO3PZSSKifk6wVWhiY2Ph6+uLL774ot14UVERYmNj8cc//hEvvfSS3udLSEjA6tWr8f7772Pu3LkP3K++vh7x8fFobW3F0aNH+UVIREbv0o1K/H3veVwrqkKglx2WzBwKf087ocMiIiKBCDYDb25uDo1G02H8fp+6VCo16HwvvPAC1q5di1OnTj20gLe0tMS8efOwfv16XL9+HT4+PgZdh8tIEhm3vpgrDlYSrJwfgZPnS7Dn2HX8/pPjiB7qiufGD8bAAYZ9VhLd1xdzhagncBnJn5HJZJ22yajVagCAk5OTQecTi8VwdnZGdXV1l/u6uroCgF77EhEZA7FIhLGhbogKcMKBH2/g8JkiZF4ux/QxgzA5ygOmJlx2koiovxDsEz8wMBCFhYWoq6trN56Tk6PbbgiNRoOSkhLY2XX9a+WioiIAgL09l2gjot7FQmqKuTG+eP9XIxDgYYvEIwX441fpOHetQq8VuYiIqPcTrICPi4uDRqNBYmKibqy5uRlJSUmIjIzU3eCqUqlQUFDQ7tjKysoO59u8eTOampowduzYh+53584dbN++HXK5HIMGDeqmd0NE9GS52FvizTlhWD43DCKRCP+7Oxd/TcxBye26rg8mIqJeTbAWmrCwMMTFxWHdunVQq9Xw9PREcnIyVCoVPvzwQ91+K1asQEZGBi5fvqwbi4mJwdSpU+Hv7w8zMzOkp6fj+++/h0KhaLeyTEJCAlJTUzFhwgS4ubmhrKwMO3fuRGVlJT777LMn+n6JiHrC0MEOCFpsh7QsJfadvIF3NmdgkkKOGWMGwdJcInR4RETUAwQr4AFgzZo12LBhA/bt24fq6moEBATgyy+/hEKheOhx06dPR3Z2Ng4ePAiNRgN3d3e89tprWLp0KUxN//OWIiIikJ2djcTERFRXV8PS0hLh4eFYunRpl9cgIuotTE3EeGq4J0YGuyDp+HUcPlOEUxdLMWvcYIwNdYNYzNW2iIj6EsGWkeytuAoNkXFjrgA3S+9ie8oVXFVWw9N5AObH+sPfw1bosMjIMFeI9GOMq9Bw2QIioj7Gy8UaK1+MxG+eCUZtgwZ/ScjGF/suoLKmUejQiIioG3RLC01LSwtSU1NRXV2NmJgY3dNUiYhIGCKRCMODnBHm64jvTt/Ed+m3cO5qBaaO9ELcCE+YSUyEDpGIiB6RwQX8mjVrkJ6ejj179gAAtFotXnnlFWRmZkKr1cLW1ha7du2Cp6dntwdLRESGkUpMMHPsYESHuiLxSAH2/lCIE7kqzJ3oh6gAGZ9GTUTUCxncQnPixAlERUXpXqelpeHMmTNYvHgx1q9fDwD48ssvuy9CIiJ6bI4DLfB/ZoZgxfwIWJpL8Le9F7Bm+1ncKmMPNBFRb2PwDHxpaSm8vLx0r48cOQK5XI633noLAHD16lUcOHCg+yIkIqJuE+Bph3cXDcPxHBWSjl/Hn/55BuPD3PDsuMGwtjQTOjwiItKDwQW8RqNpt1Rjeno6Ro8erXvt4eEBtVrdPdEREVG3E4tFmBDhjmFBTtj3QyHSsoqRkV+OZ6K9ERPpDlMTrm9ARGTMDP6UdnFxwdmzZwHcm20vKirCsGHDdNtv374NS0vL7ouQiIh6hJW5BPNj/fGnxcPh7WqNr1Ov4r1/nMHFwo5PsSYiIuNh8Az8tGnT8Pnnn6OyshJXr17FgAEDMH78eN32/Px83sBKRNSLuDta4XfPh+PctQrsTL2G9TvPIdzXEfMm+cLJjhMyRETGxuAZ+KVLl+LZZ5/FuXPnIBKJ8NFHH8HGxgYAcPfuXaSlpWHUqFHdHigREfUckUiECD8Z3v/VCMye4IP8W3fwh6/SkXj0GhqaWoQOj4iIfqZbn8Ta1taGuro6mJubQyKRdNdpjQqfxEpk3Jgr3aOqtgl7jhbg5IVSDLQyw+wJPhgV4gIxl53sM5grRPrp809ibWlpgbW1dZ8t3omI+gvbAVIsjh+CtxcoYG9jjs3f5OODrVkoUFULHRoRUb9ncAF/7NgxbNy4sd1YQkICIiMjER4ejt///vfQaDTdFiAREQnHx20g3l6gwOJpQaisacQHW7Pw1b/zUFXbJHRoRET9lsE3sW7evBkODg661wUFBfjzn/8MDw8PyOVyfPvttxg6dCgWLVrUnXESEZFAxCIRxgx1RaS/DN+cuolDZ24h64oa8aO88NQwT0hMuewkEdGTZPCn7vXr1xESEqJ7/e2330IqlWL37t346quvMHXqVOzdu7dbgyQiIuFZSE0xe4IP3v/VCAzxssOeY9fxx6/ScfaKGt14OxUREXXB4AK+uroadnZ2utc//vgjRo4ciQED7jXaDx8+HEqlsvsiJCIio+JsZ4n/ei4Uv38+HKamYmxMOo+Pd55DcUWd0KEREfULBhfwdnZ2UKlUAIDa2lqcP38eUVFRuu0tLS1obW3tvgiJiMgoBXvb471XhuGFWD8UltzFu5szsP3wFdQ18j4oIqKeZHAPfHh4OHbs2AFfX18cP34cra2tGDdunG77zZs34eTk1K1BEhGRcTI1EWNylAdGDnFG8olCpGYrcTqvDM+OG4zxYW4Qi7nsJBFRdzN4Bv6NN95AW1sbfvvb3yIpKQkzZ86Er68vAECr1SIlJQWRkZHdHigRERkva0szLHg6AO8uGgZ3Ryts+/4y3vvHGVy+dUfo0IiI+pxHepBTVVUVsrOzYW1tjWHDhunGq6ursXfvXowYMQKBgYHdGqix4IOciIwbc0V4Wq0WmZfV2JV2FbdrmhAV6IS5MT5wHGghdGj0M8wVIv0Y44OcuvVJrP0BC3gi48ZcMR7NmlYcTL+Fb0/fhBbAlBGemDLCC1IzE6FDIzBXiPRljAW8wT3w9926dQupqakoKioCAHh4eGDSpEnw9PR81FMSEVEfYiYxwYxob0SHuiLxaAH2n7yBE7klmBvji+FBThCJ2B9PRPQoHmkGfsOGDdi0aVOH1WbEYjGWLl2KN998s9sCNDacgScybswV43WlqArbU67gVlkt/OQDMT/WH14u1kKH1W8xV4j00ydm4Hfv3o0vvvgCERER+NWvfgU/Pz8AwNWrV7F582Z88cUX8PDwwKxZsx49aiIi6nP8PWzxzsJh+OF8CfYcK8Dqf57B2DBXzBrnAxsrM6HDIyLqNQyegZ81axYkEgkSEhJgatq+/m9pacGLL74IjUaDpKSkbg3UWHAGnsi4MVd6h/pGDfafvIHULCXMJCZ4ZswgTFTIYWpi8OJo9IiYK0T6McYZeIM/KQsKCjB16tQOxTsAmJqaYurUqSgoKDD0tERE1I9Ymkswb5IfVi8eDh93G+xIu4Z3Nmfg/PXbQodGRGT0DC7gJRIJ6uvrH7i9rq4OEonksYIiIqL+wdXBCsvnhOHN2aHQarX4664cbEjMQWnlg79niIj6O4ML+KFDh2Lnzp2oqKjosO327dvYtWsXwsLC9DpXc3Mz1q5di+joaISGhmLu3Lk4depUl8dt3LgRAQEBHf6MGTOm0/0TExMxZcoUDB06FE8//TQSEhL0io+IiHqeSCRCmK8j3v/VCMyN8cWVoir88at07Eq7hoamFqHDIyIyOgbfxPraa69h0aJFmDp1Kp577jndU1ivXbuGpKQk1NXVYd26dXqda+XKlTh06BAWLFgALy8vJCcnY8mSJdi2bRsiIiK6PH716tUwNzfXvf753+/bsWMH3n33XcTFxeGVV15BZmYmVq9ejaamJrz66qt6vmsiIupppiZixI3wxKhgZ+w5fh3fZ9zCjxdK8Nx4H4wJdYWYy04SEQF4xGUk09LS8P7776OkpKTduJubG9555x1MmDChy3Pk5uZizpw5WLVqFRYtWgQAaGpqQnx8PJycnB46S75x40Z8+umnOHPmDGxsbB64X2NjI8aPHw+FQoHPP/9cN/7WW28hLS0Nx44dg7W1YUuY8SZWIuPGXOk7CktqsD3lCgqKa+DlYo0XY/3hKx8odFh9BnOFSD994iZWAJg4cSJSU1Oxa9cufPzxx/j444+RmJiIlJQUlJaWYurUqV2e4+DBg5BIJJgzZ45uTCqVYvbs2cjKykJ5eXmX59BqtaitrcWDfgZJT09HVVUV5s+f3278xRdfRF1dHY4fP97lNYiISBjerjb4n5cUWDJ9CKprm/Dn/5eFLw9cxJ27TUKHRkQkqEd+EqtYLEZoaChCQ0Pbjd+5cweFhYVdHp+fnw9vb29YWVm1Gw8NvXcjU35+PpycnB56jgkTJqC+vh5WVlZ4+umnsWLFCtja2uq25+XlAQBCQkLaHRccHAyxWIy8vDxMmzaty1iJiEgYIpEIo4JdEOHniG9P38TB9CJkX1Fj2qhBiBvuAYmpidAhEhE9cY9cwD8utVoNZ2fnDuMymQwAHjoDb2Njg5dffhlhYWGQSCQ4ffo0du7ciby8PCQmJsLMzEx3DTMzs3ZFPQDdmD6z/EREJDxzM1PMGueD6FA3JKZdQ/Lx6ziRo8LzE30R6S+DiP3xRNSPCFbANzY2drrcpFQqBXCvH/5BFi5c2O51XFwc/Pz8sHr1auzduxdz58596DXuX+dh13iQh/Uj9TSZjI8cJ9IHc6XvksmsEeznhJyramzaex6fJV9AqK8jlswcikGuD74nijrHXCHSj7HlimAFvLm5OTQaTYfx+0X1/UJeXy+88ALWrl2LU6dO6Qp4c3NzNDc3d7p/U1OTwdcAeBMrkbFjrvQPbrbm+MMCBY6eVWHviet4Y/0RxES4Y+bYwRhgwWeR6IO5QqQfY7yJVbACXiaTddrColarAaDL/vdfEovFcHZ2RnV1dbtraDQaVFVVtWujaW5uRlVVlcHXICIi42EiFmOSQo4RQ5yx98R1HDlbjPS8MswcOxgTItxgIn6kdRqIiIyeXgX8P/7xD71PmJ2drdd+gYGB2LZtG+rq6trdyJqTk6PbbgiNRoOSkpJ2N6wGBQUBAC5cuIDo6Gjd+IULF9DW1qbbTkREvdcACwleeioAE8Ld8XXqVSQcvoKj54oxf5IfggbZCx0eEVG306uA/+ijjww6qT43E8XFxWHLli1ITEzUrQPf3NyMpKQkREZG6m5wValUaGhogI+Pj+7YyspK2Nu3/1DevHkzmpqaMHbsWN3YyJEjYWtri+3bt7cr4L/++mtYWlpi3LhxBr0vIiIyXnKnAXhrXjiyr6ixM+0a1u44B4W/DHMn+kJmayF0eERE3UavAn7r1q3dfuGwsDDExcVh3bp1UKvV8PT0RHJyMlQqFT788EPdfitWrEBGRgYuX76sG4uJicHUqVPh7+8PMzMzpKen4/vvv4dCoUB8fLxuP3Nzc7zxxhtYvXo13nzzTURHRyMzMxP79+/HW2+99dCHQBERUe8jEomgCHBCqI8Dvs8owr9P3UDOptt4ergHpo3ygrmZYJ2jRETd5pGexNpdmpqasGHDBhw4cADV1dUICAjA7373O4wePVq3z8svv9yhgP/DH/6A7OxslJSUQKPRwN3dHVOnTsXSpUthbm7e4Tq7du3Cli1boFQq4erqipdffhkLFix4pJh5EyuZxMyGAAAgAElEQVSRcWOu0M/duduExKPXcPpiGWwHmGFOjC9GDnHmspNgrhDpyxhvYhW0gO+NWMATGTfmCnXmmrIa21Ou4EbpXfi422B+rD+8+/myk8wVIv0YYwHPW/SJiKjP85UPxB8WRuGVqYFQVzXi//tXJrZ8k4/qWsOfB0JEJDQ2AxIRUb8gFokwNtQNUQFOOHDyBg5nFiHzcjlmjPFGbJQcpiac0yKi3oGfVkRE1K9YSE0xd6Iv3v/VCPh72GLXkWv441fpOHetAuwqJaLegAU8ERH1Sy72lvjtnDD8dk4YRCIR/nd3Lv6amIOS23VCh0ZE9FBsoSEion4t1McBQwbZIS1LiX0nC/HO5gxMUsgxY8wgWJpLhA6PiKgDFvBERNTvmZqI8dRwT4wMdkHS8es4fKYIpy6WYta4wRgb6gaxmMtOEpHxYAsNERHRT2yszLBoSiDeWTQMLvaW+NfBy1j9rzO4UlQldGhERDos4ImIiH7By8UaK1+MxNIZwbhbr8FfErLxxb4LqKxpFDo0IiK20BAREXVGJBJhxBBnhPs64rv0m/gu/RbOXa3A1JFeiBvhCTOJidAhElE/xQKeiIjoIaRmJpg5djCih7pi19EC7P2hECdyVZg70Q9RATKIROyPJ6Iniy00REREenC0tcBrM0OwYn4ELM0l+NveC1iz/SxulT3ZR6wTEbGAJyIiMkCApx3eXTQMLz8dgOKKOvzpn2ew9fvLuFvfLHRoRNRPsIWGiIjIQGKxCDER7hge5IR9JwqRll2MjLwyPDPWGzER7jA14fwYEfUcfsIQERE9IitzCeZP9sefXh2GQa7W+DrlKt77xxlcLKwUOjQi6sNYwBMRET0md9kA/P75cPzXrKHQtLRi/c5z+N/duSi/Uy90aETUB7GFhoiIqBuIRCJE+MsQMtgBh87cwr9/vIk/fJWOp4Z5YtooL1hI+ZVLRN2DnyZERETdSGIqxrRRgzA6xBV7jhXg29M3cfJCCWaP98GoEBeIuewkET0mttAQERH1ADtrKX4VPwRvL1DA3tocm7/Jx5+3ZaFAVS10aETUy7GAJyIi6kE+bgPx9gIFFk8Lwu3qRnywNQub/52HqtomoUMjol6KLTREREQ9TCwSYcxQV0T6y/DvUzdw+EwRMq+oET/KC08N84TElPNpRKQ/FvBERERPiIXUFHMm+GJcmBt2pV3DnmPXcSKnBM9P9EW4nyNE7I8nIj3wR34iIqInzNnOEv/1XCh+/3w4TExE2Jh0Hh/vPIfiijqhQyOiXoAFPBERkUCCve3xp1eH44VYPxSW3MW7mzOw/fAV1DVqhA6NiIwYW2iIiIgEZGoixuQoD4wY4oy9JwqRmq3E6bwyPDtuMMaHuUEsZlsNEbXHGXgiIiIjYGNphgVPB+DdRcPg5miFbd9fxp/+eQaXb90ROjQiMjKCFvDNzc1Yu3YtoqOjERoairlz5+LUqVMGn2fJkiUICAjABx980GFbQEBAp3++/vrr7ngLRERE3crT2Ror5kfg/8wMQX2jBh9tP4vP915ARXWD0KERkZEQtIVm5cqVOHToEBYsWAAvLy8kJydjyZIl2LZtGyIiIvQ6x9GjR5GZmfnQfaKjozFjxox2Y2FhYY8cNxERUU8SiUQYFuiEUB8HfJ9+C9+evomcaxWYMsITU0Z6QSoxETpEIhKQYAV8bm4uvvnmG6xatQqLFi0CAMycORPx8fFYt24dEhISujxHc3MzPvzwQyxevBgbN2584H6DBw/GM888012hExERPRFSiQlmRHsjOtQVu45cw/6TN3AitwRzY3wxPMiJy04S9VOCtdAcPHgQEokEc+bM0Y1JpVLMnj0bWVlZKC8v7/IcW7duRWNjIxYvXtzlvo2NjWhq4lPviIio97G3McdvngnByhcjYW0pwd/3X8RfErJxs/Su0KERkQAEK+Dz8/Ph7e0NKyurduOhoaHQarXIz89/6PFqtRqff/45li9fDgsLi4fuu3v3boSHhyM0NBTTp0/H4cOHHzt+IiKiJ83fwxbvLByGhXEBKLldj9X/PIN/fncJNXXNQodGRE+QYC00arUazs7OHcZlMhkAdDkD//HHH8Pb27vL1piIiAhMnToVcrkcJSUl2Lp1K15//XWsX78e8fHxj/4GiIiIBCAWizA+3B3DAp2w/+QNpGYpceZSOZ4ZMwgTFXKYmnCBOaK+TrACvrGxERKJpMO4VCoFgIe2u+Tm5mLv3r3Ytm1bl/1/O3bsaPf62WefRXx8PNauXYtp06YZ3D/o4DDAoP27k0xmLdi1iXoT5gr1F/81zx4zY/zw1b4L2JF2DSfOl2LJzBAoAjtOkHWGuUKkH2PLFcEKeHNzc2g0HZ80d79wv1/I/5JWq8UHH3yAp556ClFRUQZf19LSEvPmzcP69etx/fp1+Pj4GHT87du1aGvTGnzdxyWTWUOtZq8jUVeYK9TfmIuBZTODkVPggh2pV/HeptMI9XHAC5P84Gxv+cDjmCtE+hEiV8Ri0UMnjQUr4GUyWadtMmq1GgDg5OTU6XGHDx9Gbm4uli9fDqVS2W5bbW0tlEolHB0dYW5u/sBru7q6AgCqq6sfNXwiIiKjIRKJEO7riBBve6RkKrH/ZCH+8FU6Jg/zwPTRg2Ah5YPXifoSwTI6MDAQ27ZtQ11dXbsbWXNycnTbO6NSqdDW1oaFCxd22JaUlISkpCRs2rQJ48aNe+C1i4qKAAD29vaP8xaIiIiMiqmJGHEjPDEq2Bl7jl3HwfRb+PFCKZ4bPxhjhrpCzGUnifoEwQr4uLg4bNmyBYmJibp14Jubm5GUlITIyEjdDa4qlQoNDQ26VpeJEydCLpd3ON+yZcsQExOD2bNnIzg4GABQWVnZoUi/c+cOtm/fDrlcjkGDBvXcGyQiIhLIwAFSvDotCDGR7tiecgX/+PYSjmQXY/5kf6irGpB0rACVNU2wt5Fi1ngfjAp2ETpkIjKAYAV8WFgY4uLisG7dOqjVanh6eiI5ORkqlQoffvihbr8VK1YgIyMDly9fBgB4enrC09Oz03N6eHggNjZW9zohIQGpqamYMGEC3NzcUFZWhp07d6KyshKfffZZz75BIiIigXm72uB/XlLg9MUyJB69hj9vy4JYBNy/let2TRP+9d0lAGART9SLCNoUt2bNGmzYsAH79u1DdXU1AgIC8OWXX0KhUHTL+SMiIpCdnY3ExERUV1fD0tIS4eHhWLp0abddg4iIyJiJRCKMCnFBhL8jfv/pSTQ0t7bb3tzShqRjBSzgiXoRkVarffJLqvRiXIWGyLgxV4ge7NW/pD1w2+YVMQYvrUzUHxjjKjR82gMREVE/4WDT+RLNAPDulgwcz1GhWdP6wH2IyDiwgCciIuonZo33gZlp+69+M1MxxoW6AhDhn99dwu8/O4ndRwtQWdMoTJBE1CUuDEtERNRP3O9z72wVGq1WiytFVUjJVOK79Js4mH4LkQEyTI6Sw9d9INtriIwIe+ANxB54IuPGXCHSz8NypaKqAWlni3H8nAr1TS3wcrZGbJQcw4OcITHlL++pfzHGHngW8AZiAU9k3JgrRPrRJ1eamltx6mIpUrKUUFXUwcZSgvHh7oiJdIftgAf30xP1JcZYwLOFhoiIiDolNTPBhAh3jA93Q97NO0g5U4R//3gD356+iWGBToiN8sBgNxuhwyTqd1jAExER0UOJRCIED7JH8CB7lN2pR2qWEj/kluB0XhkGu9kgNkqOqAAnmJqwvYboSWALjYHYQkNk3JgrRPp53FxpaGrByfMlSM1SouxOAwYOMENMhDsmhLvDxsqsGyMlEhZbaIiIiKhPsJCaIjbKAxMVcly4XomUzCLsPVGIf/94AyOCnBEb5QEvF2uhwyTqk1jAExER0SMTi0QI9XFAqI8DSm7XISVLiR/Pl+LkhVL4yQdicpQHIvwdYSJmew1Rd2ELjYHYQkNk3JgrRPrpyVypb9TgRO699pqK6kbY20gxMVKOcWFuGGAh6ZFrEvUUY2yhYQFvIBbwRMaNuUKknyeRK21tWuRcq0BKlhL5N+/AzFSMkcEuiFXIIXd6cHFCZEyMsYBnCw0RERH1CLFYhAh/GSL8ZVCqa5GSqcSpi6U4nqNCkJcdYhVyhPk6QizmU16JDMEZeANxBp7IuDFXiPQjVK7UNmhwPEeFtGwlKmua4DjQHJMUcowNdYWlOdtryPgY4ww8C3gDsYAnMm7MFSL9CJ0rrW1tOHulAimZRbiirIZUYoLRQ++117g6WAkWF9EvGWMBzxYaIiIieuJMxGJEBTohKtAJN0vvIiWrCCdyVDiSXYwQb3vERskRMtgBYhHba4h+iTPwBuIMPJFxY64Q6ccYc6WmrhnHzhUj7Wwxqmub4WxngUkKOcYMdYWFlHOOJAxjnIFnAW8gFvBExo25QqQfY86VltY2ZF4uR2qmEgWqGpibmSA61BWTFHI421kKHR71M8ZYwPPHWSIiIjIqpiZijBzigpFDXHBdVYOUrCIcyS5GaqYSoT4OiI3ywJBBdhCxvYb6Kc7AG4gz8ETGjblCpJ/elitVtU04erYYR88Wo6ZeA1cHS8RGeWB0sAukZiZCh0d9mDHOwLOANxALeCLjxlwh0k9vzRVNSxsy8suQkqnEzbK7sJSaYlyYGyZGusPR1kLo8KgPMsYCni00RERE1GtITMUYM9QVo0NccK24GimZShw6U4Tvz9xChJ8MsQo5Ajxt2V5DfRoLeCIiIup1RCIR/OS28JPborKmEUfOFuPYORWyr6ghlw1AbJQcI4c4w0zC9hrqe9hCYyC20BAZN+YKkX76Yq40a1pxOq8MKZlFUKrrMMBCgvHhboiJcIe9jbnQ4VEvxRYaIiIioh5iJjHBuDA3jA11xeVbVTicWYRvT9/Ed6dvQREgQ2yUHL7uA9leQ70eC3giIiLqU0QiEQK97BDoZQd1VQPSspU4nlOCM5fK4eVijViFHMODnCExFQsdKtEjEfR/bnNzM9auXYvo6GiEhoZi7ty5OHXqlMHnWbJkCQICAvDBBx90uj0xMRFTpkzB0KFD8fTTTyMhIeFxQyciIqJeQGZrgecn+mH9stF4+ekANGtasfmbfPzfz09i74nrqKptEjpEIoMJOgO/cuVKHDp0CAsWLICXlxeSk5OxZMkSbNu2DREREXqd4+jRo8jMzHzg9h07duDdd99FXFwcXnnlFWRmZmL16tVoamrCq6++2l1vhYiIiIyYuZkpYiLcMSHcDXk37uBwZhH2n7yBb07dxLAgJ0yO8oC3q43QYRLpRbCbWHNzczFnzhysWrUKixYtAgA0NTUhPj4eTk5Oes2SNzc3Y/r06Zg+fTo2btyIBQsW4O2339Ztb2xsxPjx46FQKPD555/rxt966y2kpaXh2LFjsLa2Nihu3sRKZNyYK0T6Ya4AZZX1SM1S4ofzJWhsboWPmw1iozygCJDB1ITtNXSPMd7EKtj/zoMHD0IikWDOnDm6MalUitmzZyMrKwvl5eVdnmPr1q1obGzE4sWLO92enp6OqqoqzJ8/v934iy++iLq6Ohw/fvzx3gQRERH1Ws72lpg/2R/rl43BC7F+uNugwd/3X8R//+1HHPjxBmrqm4UOkahTghXw+fn58Pb2hpWVVbvx0NBQaLVa5OfnP/R4tVqNzz//HMuXL4eFRedPXsvLywMAhISEtBsPDg6GWCzWbSciIqL+y0JqislRHvjzr0fit3NC4S4bgOTj1/HWZz9i8zd5uFXWv39TQcZHsB54tVoNZ2fnDuMymQwAupyB//jjj+Ht7Y1nnnnmodcwMzODra1tu/H7Y/rM8hMREVH/IBaJEOrjiFAfR6gq6pCapcTJCyU4eb4U/vKBiI3yQIS/I0zEbK8hYQlWwDc2NkIikXQYl0qlAO71wz9Ibm4u9u7di23btj10LdcHXeP+dR52jQd5WD9ST5PJDOvXJ+qvmCtE+mGuPJhMZo2wIBf8ur4ZhzNu4d8nC/H53guQ2Vlg2mhvPDXSC9aWZkKHSU+IseWKYAW8ubk5NBpNh/H7RfX9Qv6XtFotPvjgAzz11FOIiorq8hrNzZ33rzU1NT3wGg/Dm1iJjBtzhUg/zBX9RQc7Y3SQE85dq0BKZhH++U0etn9/CSODXRAbJYdcJtzkHvU8Y7yJVbACXiaTddrColarAQBOTk6dHnf48GHk5uZi+fLlUCqV7bbV1tZCqVTC0dER5ubmkMlk0Gg0qKqqatdG09zcjKqqqgdeg4iIiOjnxGIRIv1liPSXQVlei5SsIpy6WIrjOSoEedkhNkqOMB9HiMV8yiv1PMGauAIDA1FYWIi6urp24zk5ObrtnVGpVGhra8PChQsxadIk3R8ASEpKwqRJk5CRkQEACAoKAgBcuHCh3TkuXLiAtrY23XYiIiIifcmdBmDRlCCsXzYGz40fjNLKemzccx6rvjyFQxm3UN/YscOAqDsJNgMfFxeHLVu2IDExUbcOfHNzM5KSkhAZGam7wVWlUqGhoQE+Pj4AgIkTJ0Iul3c437JlyxATE4PZs2cjODgYADBy5EjY2tpi+/btiI6O1u379ddfw9LSEuPGjevhd0lERER91QALCaaNGoS4EZ7IvnKvvWZH2jUknyjEmKEumKSQw9XBqusTERlIsAI+LCwMcXFxWLduHdRqNTw9PZGcnAyVSoUPP/xQt9+KFSuQkZGBy5cvAwA8PT3h6enZ6Tk9PDwQGxure21ubo433ngDq1evxptvvono6GhkZmZi//79eOutt2BjwyeuERER0eMxEYsxLNAJwwKdcKO0BqmZShzPUSEtuxghg+0Rq/BAyGB7iB+y8AaRIQQr4AFgzZo12LBhA/bt24fq6moEBATgyy+/hEKh6LZrvPjii5BIJNiyZQtSU1Ph6uqKt99+GwsWLOi2axAREREBwCAXGyyOH4I5Mb44eq4YR7KLsSExB872lohVyDE6xAUWUkHLL+oDRFqt9skvqdKLcRUaIuPGXCHSD3PlyWhpbUPmpXIczlSisKQGFlITRA91wySFO5zsLIUOj/TAVWiIiIiI+hFTEzFGBrtgZLALClTVSM1UIi1biZTMIoT5OmJSlBxDvOwe+lwbol9iAU9ERET0BPi4DYTPjIH32mvOFuPouWKc21EBN0crxCrkGBXsAqmZidBhUi/AFhoDsYWGyLgxV4j0w1wRnqalFRn55TicWYRbZbWwMjfF2DA3TIx0h+NAC6HDo5+whYaIiIiIAAASUxOMGeqK0SEuuKqsRkqWEocyivB9xi1E+skQGyWHv4ct22uoAxbwRERERAISiUTw97CFv4ctblc34sjZYhw7V4ysK2p4OA1ArEKOkcHOkJiyvYbuYQuNgdhCQ2TcmCtE+mGuGLcmTSvS88pwOLMIxeo6DLCQYHy4GyZGymFnLRU6vH6FLTRERERE1CWpxATjwtwwNtQVl25VISWzCN+euomD6begCJAhNsoDPm42bK/pp1jAExERERkpkUiEIC87BHnZQV3VgLRsJY7nlCAjvxyDXKwxOcoDUYFOkJiKhQ6VniC20BiILTRExo25QqQf5krv1djcgh8vlCIlU4nSynrYWJlhQrgbYiLcMXAA22u6G1toiIiIiOixmJuZYmKkHBMi3JF3oxIpmUrsP3kD35y6ieFBToiN8oC3q43QYVIPYgFPRERE1AuJRSKEeDsgxNsBZZX1SMlS4ofzJTh1sQw+7jaIVXhAESCDqQnba/oattAYiC00RMaNuUKkH+ZK39TQ1IIfckuQmqVEeVUD7KyliIlwx7hwN9hYmgkdXq9kjC00LOANxAKeyLgxV4j0w1zp29q0WuQW3EZqZhEu3rgDUxMxRg5xRmyUHJ7O1kKH16sYYwHPFhoiIiKiPkYsEiHc1xHhvo4orqhDapYSP14owQ/nS+DvYYvJUXKE+znCRMz2mt6IM/AG4gw8kXFjrhDph7nS/9Q1anAi5157ze2aRjjYSDFRIcfYUDcMsJAIHZ7RMsYZeBbwBmIBT2TcmCtE+mGu9F9tbVqcvVqB1KwiXLpVBTNTMUaHuGCSQg532YOLxv7KGAt4ttAQERER9SNisQiKABkUATLcKruL1CwlTl4oxdFzKgR52WFylAdCfRwgFvMpr8aKM/AG4gw8kXFjrhDph7lCP3e3vhnHc1RIyy7GnbtNkNmaY5LCA9FDXWFp3r/ne41xBp4FvIFYwBMZN+YKkX6YK9SZltY2ZF9RIyVLiWvKakjNTBAd4oqJCne4OlgJHZ4gjLGA798/UhERERGRjqmJGMODnDE8yBk3SmuQkqnEsZxipGYrETLYHpOjPBDsbQ+xiO01QuIMvIE4A09k3JgrRPphrpC+quuacexsMY6cLUZ1XTNc7C0xSSHHmKEuMDfr+3PBxjgDzwLeQCzgiYwbc4VIP8wVMlRLaxvOXCpHSmYRCkvuwkJqgrGhbpiokMPJ1kLo8HqMMRbwff/HJiIiIiJ6bKYmYowKdsGoYBcUFFcjJUuJ1CwlDp8pQpivI2Kj5AjysoOI7TU9jgU8ERERERnEx30gfNwHYm6ML46cLcbRs8U4d60C7o5WmBQlx6hgF0glJkKH2WexhcZAbKEhMm7MFSL9MFeoO2laWpGed6+95lZ5LazMTTEuzA0xke5wHNi722vYQvMLzc3N+OSTT7Bv3z7U1NQgMDAQy5cvx6hRox563P79+7F7924UFBSguroaTk5OGDFiBF5//XW4u7u32zcgIKDTc7z33nt44YUXuu29EBEREfVXElMTRIe6YsxQF1xVVuNwZhEOZtzCwYxbiPSXIVYhh7+HLdtruomgBfzKlStx6NAhLFiwAF5eXkhOTsaSJUuwbds2REREPPC4S5cuwdnZGePHj8fAgQOhUqmwa9cuHD16FPv374dMJmu3f3R0NGbMmNFuLCwsrEfeExEREVF/JRKJ4O9hC38PW9yubkRathLHc1TIuqyGp9MATIqSY+QQZ0hM2V7zOARrocnNzcWcOXOwatUqLFq0CADQ1NSE+Ph4ODk5ISEhwaDzXbx4EbNmzcJ///d/Y/HixbrxgIAALFiwAG+//Xa3xM0WGiLjxlwh0g9zhZ6UJk0rTl8sRUqmEsUVdRhgIcGECDfERMhhZy0VOrwusYXmZw4ePAiJRII5c+boxqRSKWbPno2//vWvKC8vh5OTk97nc3NzAwDU1NR0ur2xsREikQhSqfH/RyEiIiLqK6QSE4wPd8e4MDdcunkHhzOV+ObHm/ju9C0oAmSYHOWBwW42bK8xgGAFfH5+Pry9vWFl1f6xvKGhodBqtcjPz++ygK+qqkJraytUKhU+++wzAOi0f3737t3Ytm0btFot/P398cYbb2Dy5Mnd92aIiIiI6KFEIhGCBtkjaJA9yqsakJalxIlcFTLyy+Htao3YKA8MC3SCqYlY6FCNnmAFvFqthrOzc4fx+/3r5eXlXZ7j6aefRlVVFQDA1tYW77zzDkaOHNlun4iICEydOhVyuRwlJSXYunUrXn/9daxfvx7x8fHd8E6IiIiIyBBOthaYN8kPM8d64+T5UqRmKbHpQB52pV3DhAh3TIhwx0ArM6HDNFqCFfCNjY2QSCQdxu+3uDQ1NXV5jk8//RT19fUoLCzE/v37UVdX12GfHTt2tHv97LPPIj4+HmvXrsW0adMM/nXNw/qReppMZi3YtYl6E+YKkX6YK2QM5rnbYe5TgTh3RY39Jwqw74dCfHPqJsaGu2HGWB/4etgKHaLR5YpgBby5uTk0Gk2H8fuFuz696sOGDQMAjB8/HpMmTcL06dNhaWmJl1566YHHWFpaYt68eVi/fj2uX78OHx8fg+LmTaxExo25QqQf5goZGw8HCyybGYLSynqkZirxw/kSHMlSwtd9IGKj5Ij0lwnSXmOMN7EK1mQkk8k6bZNRq9UAYNANrADg4eGB4OBgHDhwoMt9XV1dAQDV1dUGXYOIiIiIepaLvSVefMof618bg3mT/FBd14Qv9l3Eii9O4ZtTN3C3vlnoEAUn2Ax8YGAgtm3bhrq6unY3subk5Oi2G6qxsRENDQ1d7ldUVAQAsLe3N/gaRERERNTzLM1N8dQwD8Qq5MgtuI2UrCLsOXYd+364gZHBzpgc5QEPJ+Fam4Uk2Ax8XFwcNBoNEhMTdWPNzc1ISkpCZGSk7gZXlUqFgoKCdsdWVlZ2ON+FCxdw6dIlBAcHP3S/O3fuYPv27ZDL5Rg0aFA3vRsiIiIi6glisQjhfo54a14E3l88HNFDXZCRV4Z3t2Tgo4RsZF1WC9LeLCTBZuDDwsIQFxeHdevWQa1Ww9PTE8nJyVCpVPjwww91+61YsQIZGRm4fPmybiwmJgZTpkyBv78/LC0tce3aNezZswdWVlZ47bXXdPslJCQgNTUVEyZMgJubG8rKyrBz505UVlbqlp0kIiIiot7BXTYAC+ICMWu8D07kqpCWpcRnyefhYGOOSQo5xoa5wsq84yIpfY1gBTwArFmzBhs2bMC+fftQXV2NgIAAfPnll1AoFA89bv78+Th16hRSUlLQ2NgImUyGuLg4vPbaa/Dw8NDtFxERgezsbCQmJqK6uhqWlpYIDw/H0qVLu7wGERERERmnARYSTBnhhaeGeeDc1QqkZCqx68g17P3hOkaHuGKSQg53R6uuT9RLibRabf/6ncNj4io0RMaNuUKkH+YK9TW3yu4iJUuJ0xfL0NLahuBBdpgU5YFQHweIH+Mpr8a4Cg0LeAOxgCcybswVIv0wV6ivqqlvxvFzKhw5W4w7d5vgZGuBSQo5okNdYSE1vPmEBXwfwAKeyLgxV4j0w1yhvq6ltQ3ZV9RIyVTiWnE1pGYmiB56r73Gxd5S7/MYYwEvaA88EREREVFPMDURY3iQM4YHOaOwpAYpmUU4erYYqVlKhPo4IFYhxxBv+8dqrxEKZ+ANxBl4IuPGXCHSD3OF+vaBKZcAAAtVSURBVKPq2iYc/am9pqauGa4OlpikkGN0iAvMzTqf1zbGGXgW8AZiAU9k3JgrRPphrlB/pmlpQ+alchzOLMKN0ruwkJpibKgrJirkcLK1AACculiKpGMFqKxpgr2NFLPG+2BUsMsTiY8FfDdjAU9k3JgrRPphrhABWq0WBap77TWZl9TQarUI93OEm4MlDmcq0dzSptvXzFSMhVMCn0gRzx54IiIiIqJOiEQi+LoPhK/7QFTGNOLouWIcPavC2asVHfZtbmlD0rGCJzYL/zBioQMgIiIiIhKavY05Zo3zwbrXRj9wn9s1TU8wogdjAU9ERERE9BMziQkcbKSdbnvQ+JPGAp6IiIiI6GdmjfeBmWn7MtnMVIxZ430Eiqg99sATEREREf3M/T53oVah6QoLeCIiIiKiXxgV7IJRwS5GuWITW2iIiIiIiHoRFvBERERERL0IC3giIiIiol6EBTwRERERUS/CAp6IiIiIqBdhAU9ERERE1IuwgCciIiIi6kVYwBMRERER9SIs4ImIiIiIehE+idVAYrGoX16bqDdhrhDph7lCpJ8nnStdXU+k1Wq1TygWIiIiIiJ6TGyhISIiIiLqRVjAExERERH1IizgiYiIiIh6ERbwRERERES9CAt4IiIiIqJehAU8EREREVEvwgKeiIiIiKgXYQFPRERERNSLsIAnIiIiIupFWMATEREREfUipkIHQJ0rLy/H1q1bkZOTgwsXLqC+vh5bt27FiBEjhA6NyKjk5uYiOTkZ6enpUKlUsLW1RUREBH7729/Cy8tL6PCIjMb58+fxxRdfIC8vD7dv34a1tTUCAwOxbNkyREZGCh0ekdHatGkT1q1bh8DAQOzbt0/ocACwgDdahYWF2LRpE7y8vBAQEICzZ88KHRKRUfrqq6+QnZ2NuLg4BAQEQK1WIyEhATNnzsTu3bvh4+MjdIhERqGoqAitra2YM2cOZDIZ7t69iwMHDuCll17Cpk2bMGbMGKFDJDI6arUaf/vb32BpaSl0KO2ItFqtVuggqKPa2lpoNBrY2dkhJSUFy5Yt4ww8USeys7MREhICMzMz3diNGzcwffp0TJs2DX/5y18EjI7IuDU0NCA2NhYhISH4+9//LnQ4REZn5cqVUKlU0Gq1qKmpMZoZePbAG6kBAwbAzs5O6DCIjF5kZGS74h0ABg0aBD8/PxQUFAgUFVHvYGFhAXt7e9TU1AgdCpHRyc3Nxf79+7Fq1SqhQ+mABTwR9TlarRYVFRX8IZioE7W1taisrMT169fx8ccf48qVKxg1apTQYREZFa1Wi/fffx8zZ85EUFCQ0OF0wB54Iupz9u/fj7KyMixfvlzoUIiMzv/8z//g+++/BwBIJBLMmzcPv/nNbwSOisi47N27F9euXcNnn30mdCidYgFPRH1KQUEBVq9eDYVCgWeeeUbocIiMzrJly/D888+jtLQU+/btQ3NzMzQaTYdWNKL+qra2FuvXr8evf/1rODk5CR1Op9hCQ0R9hlqtxtKlSzFw4EB88sknEIv5EUf0SwEBARgzZgyee+45bN68GRcvXjTKHl8iofztb3+DRCLBK6+88v+3dzchUe1/HMc/amVQSmgThNqDBYoPOC560FDMUYgwbBFI6hRpA2UGFrYpWgRFQRbRlGC5yDa5MEGYRWmNYDVQECWRSVhWDj1YmmX5kOn8F5c7N+94+7upmZPv1+58z3ec7xmQ+XDmd87x9yj/iW83AH+EwcFB2Ww2DQ4Oqra2ViaTyd8jAQFv9uzZslgsam5u1sjIiL/HAfyut7dXdXV1Kiws1IcPH+R2u+V2uzU6OqqxsTG53W59+vTJ32OyhAaA8Y2OjmrXrl168eKFLl26pNjYWH+PBBjGyMiIPB6Pvn79qrlz5/p7HMCv+vr6NDY2pqqqKlVVVfnst1gsstlsqqys9MN0/yDAAzC08fFxVVRU6OHDh6qurpbZbPb3SEBA6u/vV0RExKTaly9fdP36dS1evFiRkZF+mgwIHNHR0VNeuHrmzBkNDQ3p4MGDWrZs2e8f7F8I8AGsurpakrz3sm5qatL9+/cVHh6u4uJif44GBIwTJ07I6XRq/fr1GhgYmPSQjXnz5iknJ8eP0wGBo6KiQqGhoUpNTZXJZNKbN2/U2Niot2/f6vTp0/4eDwgIYWFhU35v1NXVKSQkJGC+U3gSawCLi4ubsh4VFSWn0/mbpwECk9Vq1b1796bcx/8K8I+GhgY1NTWpq6tLnz9/VlhYmMxms0pKSrR69Wp/jwcENKvVGlBPYiXAAwAAAAbCXWgAAAAAAyHAAwAAAAZCgAcAAAAMhAAPAAAAGAgBHgAAADAQAjwAAABgIAR4AAAAwEAI8ACAgGe1WpWdne3vMQAgIMzy9wAAAP+4e/eutm3b9p/7Q0JC1NHR8RsnAgBMBwEeAGa4vLw8ZWZm+tSDg/mRFgACEQEeAGa4hIQE5efn+3sMAMA0cXoFAPBTbrdbcXFxstvtcjgc2rRpk5KTk5WVlSW73a7v37/7vKazs1N79uzRmjVrlJycrI0bN+rixYsaHx/36X3//r2OHj0qi8WipKQkpaWlaceOHbpz545P77t377R//36tWrVKKSkpKi0tVXd39y85bgAIVJyBB4AZbnh4WP39/T71OXPmaP78+d5tp9Opnp4eFRUVaeHChXI6nTp37pxev36t48ePe/sePXokq9WqWbNmeXtbW1tVVVWlzs5OnTp1ytvrdru1detW9fX1KT8/X0lJSRoeHlZ7e7tcLpfWrVvn7R0aGlJxcbFSUlK0b98+ud1uXb58WWVlZXI4HAoJCflFnxAABBYCPADMcHa7XXa73aeelZWlmpoa73ZnZ6caGhqUmJgoSSouLlZ5ebkaGxtVUFAgs9ksSTp27Ji+ffum+vp6xcfHe3srKirkcDi0ZcsWpaWlSZKOHDmi3t5e1dbWKiMjY9L7T0xMTNr++PGjSktLZbPZvLWIiAidPHlSLpfL5/UA8KciwAPADFdQUKANGzb41CMiIiZtp6ene8O7JAUFBWnnzp26ceOGWlpaZDab1dfXpwcPHig3N9cb3v/u3b17t65du6aWlhalpaVpYGBAt27dUkZGxpTh+98X0QYHB/vcNWft2rWSpJcvXxLgAcwYBHgAmOGWLl2q9PT0/9u3YsUKn9rKlSslST09PZL+WhLzY/1HsbGxCg4O9va+evVKHo9HCQkJ05pz0aJFCg0NnVRbsGCBJGlgYGBafwMA/gRcxAoAMISfrXH3eDy/cRIA8C8CPABgWp49e+ZT6+rqkiTFxMRIkqKjoyfVf/T8+XNNTEx4e5csWaKgoCA9efLkV40MAH8kAjwAYFpcLpceP37s3fZ4PKqtrZUk5eTkSJIiIyOVmpqq1tZWPX36dFLvhQsXJEm5ubmS/lr+kpmZqba2NrlcLp/346w6AEyNNfAAMMN1dHSoqalpyn1/B3NJio+P1/bt21VUVCSTyaSbN2/K5XIpPz9fqamp3r5Dhw7JarWqqKhIhYWFMplMam1t1e3bt5WXl+e9A40kHT58WB0dHbLZbNq8ebMSExM1Ojqq9vZ2RUVF6cCBA7/uwAHAoAjwADDDORwOORyOKfc1Nzd7155nZ2dr+fLlqqmpUXd3tyIjI1VWVqaysrJJr0lOTlZ9fb3Onj2rK1euaGhoSDExMaqsrFRJScmk3piYGF29elXnz59XW1ubmpqaFB4ervj4eBUUFPyaAwYAgwvy8BslAOAn3G63LBaLysvLtXfvXn+PAwAzHmvgAQAAAAMhwAMAAAAGQoAHAAAADIQ18AAAAICBcAYeAAAAMBACPAAAAGAgBHgAAADAQAjwAAAAgIEQ4AEAAAADIcADAAAABvI/lO/2/JEC/kkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YYW_gag9Y7P","executionInfo":{"status":"ok","timestamp":1632389049260,"user_tz":-540,"elapsed":951,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"b099d6be-7518-40ae-a83f-b62703aec7d1"},"source":["import pandas as pd\n","\n","# Load the dataset into a pandas dataframe.\n","#PATH = '/content/drive/MyDrive/gh/klue/DATA'\n","#df = pd.read_csv(PATH + \"/BoolQ/SKT_BoolQ_Train.tsv\", sep='\\t')\n","df = pd.read_csv(PATH + \"/BoolQ/SKT_BoolQ_Dev.tsv\", sep='\\t')\n","# Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# Create sentence and label lists\n","#sentences = df.sentence.values\n","#labels = df.acceptability_label.values\n","\n","# Get the lists of sentences and their labels.\n","passages = df.Text.values\n","questions = df.Question.values\n","labels = df['Answer(FALSE = 0, TRUE = 1)'].values\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for question, passage in zip(questions, passages):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        question,\n","                        passage,            # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 700\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jc5HhwZW9yB5","executionInfo":{"status":"ok","timestamp":1632389617716,"user_tz":-540,"elapsed":5815,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"a51678cb-4516-491e-ec8d-29601d73d421"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","pred_flat,labels_flat = [],[]\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","  pred_flat.extend(np.argmax(logits,axis=1).flatten())\n","  labels_flat.extend(label_ids.flatten())\n","\n","print('    DONE.')"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 700 test sentences...\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"5G67JAlu-FnB","executionInfo":{"status":"ok","timestamp":1632389073391,"user_tz":-540,"elapsed":368,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}}},"source":["#print('Positive samples: %d of %d (%.2f%%)' % (df.acceptability_label.sum(), len(df.acceptability_label), (df.acceptability_label.sum() / len(df.acceptability_label) * 100.0)))"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xyPFTnR-G7I","executionInfo":{"status":"ok","timestamp":1632389775061,"user_tz":-540,"elapsed":256,"user":{"displayName":"­김동후","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05428640934514761408"}},"outputId":"b23faa16-d21e-4839-f44b-272f266799bc"},"source":["def flat_accuracy2(preds, labels):\n","    print(type(preds[0]))\n","    print(type(labels[0]))\n","    #pred_flat = preds\n","    #labels_flat = labels\n","    return np.sum(np.array(preds) == np.array(labels)) / len(labels)\n","\n","print(flat_accuracy2(pred_flat,labels_flat))\n","\n","#np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.int64'>\n","<class 'numpy.int64'>\n","0.6585714285714286\n"]}]},{"cell_type":"code","metadata":{"id":"X49_PIB9ACZr"},"source":[""],"execution_count":null,"outputs":[]}]}